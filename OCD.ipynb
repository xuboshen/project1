{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四个数据集：OCD_90_120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来自Dr.SheN贴心的注释：\n",
    "\n",
    "每次训练的时候，请在上方选择：Kernel-Restart and Run All哦，不然可能出现一些小问题\n",
    "\n",
    "默认算法：线性回归\n",
    "\n",
    "默认数据集：PPMI\n",
    "\n",
    "默认training set：validation set：test set = 8：1：1\n",
    "\n",
    "默认优化算法：SGD\n",
    "\n",
    "默认loss：MSELoss（如果是深度方法，由于是二分类问题，建议改成BCE Loss）\n",
    "\n",
    "这份代码默认实现的是线性回归的训练代码，如果要改成深度方法的代码，要注意outputs = net(inputs)的前向传播的维度和输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要增加的东西：\n",
    "- K-fold\n",
    "- 可以尝试PCA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Sep 15 16:14:34 2021',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'NC': array([[[ 1.71912421e+00,  2.21270511e+00,  1.68960500e+00, ...,\n",
       "           1.33252308e+00,  4.65957680e-01, -6.88871296e-01],\n",
       "         [ 2.13050475e+00,  2.21960901e+00,  1.29836480e+00, ...,\n",
       "           2.98712160e-01, -5.18081209e-01, -1.11117704e+00],\n",
       "         [ 1.08634990e-01,  7.12645125e-01,  1.27033019e+00, ...,\n",
       "           1.36868045e+00,  1.27166899e+00,  7.43193650e-01],\n",
       "         ...,\n",
       "         [ 6.08532543e-01,  6.31457518e-01, -2.19204338e-01, ...,\n",
       "           1.33883737e+00,  2.30229148e+00,  1.95279573e+00],\n",
       "         [-2.64155910e-02, -6.53182273e-02, -4.18536691e-02, ...,\n",
       "           5.92263029e-01,  7.59156459e-01,  4.98339401e-01],\n",
       "         [-4.85977772e-02,  3.56739070e-02, -1.00098887e-01, ...,\n",
       "           8.56619253e-01,  1.01913200e+00,  6.93397817e-01]],\n",
       " \n",
       "        [[-1.43473728e+00, -1.83086463e+00, -1.62762613e+00, ...,\n",
       "          -3.04072221e+00, -1.64656248e+00, -1.13794282e-01],\n",
       "         [-3.42455955e-01, -1.27224205e+00, -2.03363482e+00, ...,\n",
       "          -2.56290313e+00, -1.60663532e+00, -3.75550534e-01],\n",
       "         [-1.08792683e+00,  9.26256480e-01,  2.59595093e+00, ...,\n",
       "          -1.32600568e+00, -3.47635967e-01, -5.08257586e-02],\n",
       "         ...,\n",
       "         [ 2.53605896e-01,  1.97459811e+00,  2.66550741e+00, ...,\n",
       "          -6.80276180e+00, -4.60415513e+00, -1.86716543e+00],\n",
       "         [ 2.27413113e-01,  1.19351584e+00,  1.81382702e+00, ...,\n",
       "          -2.58329573e+00, -1.18037108e+00,  1.27488452e-01],\n",
       "         [ 1.23250412e-01,  1.46394495e+00,  2.16917196e+00, ...,\n",
       "          -1.87341924e+00, -1.73791005e-01,  9.19119221e-01]],\n",
       " \n",
       "        [[-2.75818797e+00, -2.50509593e+00, -3.21536325e+00, ...,\n",
       "           1.73214225e+00,  3.16760251e-01, -6.51127496e-01],\n",
       "         [-4.93734239e-01, -1.00937988e+00, -2.27483127e+00, ...,\n",
       "           1.67965315e+00,  2.73295532e-01, -8.83104814e-01],\n",
       "         [ 7.91451993e-01,  9.19076131e-01, -1.31596629e-02, ...,\n",
       "           3.97335676e-01, -2.51233958e-02, -4.04155709e-01],\n",
       "         ...,\n",
       "         [ 2.07434191e+00,  4.24382477e-01, -1.65694124e+00, ...,\n",
       "           1.92211405e+00, -4.61384619e-01, -2.01101065e+00],\n",
       "         [-4.77415640e-01,  4.09007988e-01,  4.13038354e-01, ...,\n",
       "           1.00456713e+00,  1.12191393e+00,  7.74440199e-01],\n",
       "         [-4.25523495e-01,  2.39141968e-01,  5.72498211e-02, ...,\n",
       "           1.40594623e+00,  9.79297770e-01,  1.92928277e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.00322164e+00,  1.32062696e+00, -1.20107812e+00, ...,\n",
       "          -2.21350696e-01, -8.25857342e-01, -1.11506215e+00],\n",
       "         [ 3.07114392e+00,  7.13283910e-01, -3.06681133e+00, ...,\n",
       "          -1.28988390e+00, -2.10567221e+00, -2.07810792e+00],\n",
       "         [-1.30661287e+00, -1.26753112e+00, -1.76573608e+00, ...,\n",
       "           9.24993373e-02,  1.74186976e-01, -5.73660558e-02],\n",
       "         ...,\n",
       "         [-4.50954942e-03,  8.89805958e-01,  3.87964985e-01, ...,\n",
       "          -1.97736313e+00, -2.37122448e+00, -1.99854423e+00],\n",
       "         [ 1.05615825e+00,  1.31356680e+00,  6.53297164e-01, ...,\n",
       "          -6.98143050e-01, -4.71317256e-01, -1.70283590e-01],\n",
       "         [ 1.13865805e+00,  1.38809626e+00,  6.18047856e-01, ...,\n",
       "          -6.01474141e-01, -7.72903598e-01, -8.15269360e-01]],\n",
       " \n",
       "        [[ 4.92982253e+00,  5.33223418e+00,  3.56729401e+00, ...,\n",
       "           5.81713891e+00,  3.98616814e+00,  1.58396813e+00],\n",
       "         [ 5.78199717e+00,  6.73898478e+00,  4.65824405e+00, ...,\n",
       "           3.98562554e+00,  2.35267321e+00,  3.49483594e-01],\n",
       "         [-1.87581432e+00, -2.07746142e+00, -1.43527171e+00, ...,\n",
       "           1.52632599e+00,  8.63842742e-01,  7.66858536e-02],\n",
       "         ...,\n",
       "         [ 4.34772587e+00,  5.28106433e+00,  3.62708616e+00, ...,\n",
       "           4.93750919e+00,  2.49859849e+00,  2.68883557e-01],\n",
       "         [-1.31854722e-02,  6.67528475e-01,  7.30400610e-01, ...,\n",
       "           3.09388880e+00,  2.17096645e+00,  8.40169674e-01],\n",
       "         [-4.92330641e-01,  5.22953892e-01,  1.24426809e+00, ...,\n",
       "           3.06979706e+00,  2.72147512e+00,  1.60068963e+00]],\n",
       " \n",
       "        [[ 2.83482795e+00,  3.06775701e+00,  1.42700422e+00, ...,\n",
       "          -8.34471296e-01, -2.63354796e+00, -1.79089587e+00],\n",
       "         [ 2.85107942e-02,  6.98297881e-01,  3.13283703e-01, ...,\n",
       "          -3.27400371e+00, -4.08609914e+00, -2.49824035e+00],\n",
       "         [ 1.38651030e+00,  3.57760057e+00,  5.02624537e+00, ...,\n",
       "          -2.48822811e-01, -9.17650029e-01, -5.16849638e-01],\n",
       "         ...,\n",
       "         [-1.39422262e+00, -1.28886767e+00, -9.50982097e-01, ...,\n",
       "          -3.45151982e+00, -3.70725188e+00, -1.73127313e+00],\n",
       "         [ 1.83361557e+00,  2.78016413e+00,  2.38297442e+00, ...,\n",
       "          -1.42697740e-01, -1.91345151e+00, -1.90336545e+00],\n",
       "         [ 1.38869388e+00,  2.18317983e+00,  1.68485712e+00, ...,\n",
       "          -2.30966450e+00, -3.12439287e+00, -2.02557134e+00]]]),\n",
       " 'OCD': array([[[-1.20367661e+00, -2.05000232e-02,  7.62054463e-01, ...,\n",
       "          -6.21361972e-01,  3.91518621e-01,  5.94437580e-01],\n",
       "         [-1.97359270e+00, -9.34904524e-01, -5.19327727e-01, ...,\n",
       "          -1.29559736e+00, -9.03280051e-01, -2.38543626e-01],\n",
       "         [-1.32774450e+00, -7.21536244e-01,  1.50424804e-01, ...,\n",
       "          -4.01522474e-01, -5.16829367e-02,  4.51255254e-03],\n",
       "         ...,\n",
       "         [-3.15056520e+00, -1.46969550e+00,  8.94330091e-01, ...,\n",
       "          -4.79040246e-01,  9.09953266e-01,  1.36520135e+00],\n",
       "         [-6.25374061e-01, -3.24453057e-01, -3.53175118e-02, ...,\n",
       "          -9.45654454e-02, -1.59653322e-01, -4.15525994e-02],\n",
       "         [-4.77810390e-01, -6.23293234e-01, -6.32778844e-01, ...,\n",
       "          -9.50993575e-01, -3.45348773e-01,  2.37926390e-02]],\n",
       " \n",
       "        [[-1.37416837e+00, -1.11168238e+00, -1.28185094e+00, ...,\n",
       "           6.35109878e-01,  9.78337109e-01,  5.67477075e-01],\n",
       "         [-1.15999017e+00, -1.45193943e+00, -2.01868670e+00, ...,\n",
       "           1.26471957e+00,  1.35730345e+00,  8.21721727e-01],\n",
       "         [-1.52946061e-01,  2.29190241e-02, -4.64194452e-01, ...,\n",
       "          -7.33270037e-01, -8.33077437e-01, -7.56575134e-01],\n",
       "         ...,\n",
       "         [ 5.37455458e-01, -2.96904204e-02, -6.82295506e-01, ...,\n",
       "           2.55579364e-01,  1.27745603e+00,  1.38040658e+00],\n",
       "         [-5.48784187e-01, -7.24593217e-01, -4.99843305e-01, ...,\n",
       "          -1.31985811e-01, -2.80835187e-01, -4.30324525e-01],\n",
       "         [-1.06372179e-01,  2.34906349e-01,  6.61893621e-01, ...,\n",
       "          -9.50784643e-01, -6.13692970e-01, -3.66452515e-01]],\n",
       " \n",
       "        [[ 4.71412206e-01,  8.98582023e-01,  8.66916477e-01, ...,\n",
       "           1.26696000e+00,  1.22745497e+00,  7.17379414e-01],\n",
       "         [ 9.25837855e-01,  8.23082174e-01,  3.78485263e-01, ...,\n",
       "           4.56330437e-01,  8.69145858e-01,  7.89340190e-01],\n",
       "         [-3.75658895e-01, -4.53230385e-01,  4.54203840e-02, ...,\n",
       "          -3.25736354e-01,  3.63725231e-02,  2.57676571e-01],\n",
       "         ...,\n",
       "         [-1.62134669e+00, -7.63446080e-01,  7.38285166e-01, ...,\n",
       "           1.20962498e+00,  1.72146180e+00,  1.37307908e+00],\n",
       "         [ 5.19249401e-01,  6.15969272e-01,  3.95368579e-01, ...,\n",
       "           6.10370669e-01,  7.29094071e-01,  5.43858189e-01],\n",
       "         [-1.03002241e-01,  1.07271725e-01,  4.94034127e-01, ...,\n",
       "           5.09703153e-01,  7.81620019e-01,  5.88118131e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.40900052e+00,  2.36418166e+00,  1.03504857e+00, ...,\n",
       "           1.30199226e+00,  3.18110613e+00,  2.78050218e+00],\n",
       "         [-1.64996377e-01,  2.18061630e+00,  3.35739731e+00, ...,\n",
       "           3.84756997e+00,  2.44797738e+00,  6.11362442e-01],\n",
       "         [ 1.55468265e-01, -1.61512315e+00, -2.85032055e+00, ...,\n",
       "           2.38431196e+00,  1.90672340e+00,  5.67414167e-01],\n",
       "         ...,\n",
       "         [-4.40187227e+00, -5.40751089e+00, -4.42897279e+00, ...,\n",
       "           2.19555670e+00,  2.55784616e+00,  1.57710698e+00],\n",
       "         [-1.45566336e+00, -1.11867044e+00, -9.16062225e-01, ...,\n",
       "           5.11876887e-01,  4.52017239e-02, -5.19810130e-01],\n",
       "         [-3.63823805e-01, -4.97376051e-01, -6.26201687e-01, ...,\n",
       "           2.54741928e+00,  2.89859282e+00,  1.85100156e+00]],\n",
       " \n",
       "        [[-1.70197643e+00, -1.49633228e+00, -1.10851970e+00, ...,\n",
       "          -1.23782012e-01, -3.31090415e-01, -2.65185203e-01],\n",
       "         [-1.53783483e+00, -6.89799625e-01, -3.85982689e-01, ...,\n",
       "          -1.62743889e-01, -5.07553452e-01, -5.16133959e-01],\n",
       "         [ 3.45790809e+00,  1.25457043e+00, -1.86769483e+00, ...,\n",
       "          -8.84217695e-01, -2.20613226e+00, -2.09149830e+00],\n",
       "         ...,\n",
       "         [ 8.10452875e-01, -9.91237660e-03, -1.90484986e+00, ...,\n",
       "          -1.98676998e+00, -3.03659586e+00, -2.62044029e+00],\n",
       "         [-1.15251566e-01, -2.34275128e-01, -3.85880984e-01, ...,\n",
       "          -3.71419977e-01, -8.31010004e-01, -9.35713126e-01],\n",
       "         [-1.02098984e-01, -3.95348999e-01, -9.47365042e-01, ...,\n",
       "          -3.40534214e-01, -1.13857672e+00, -1.55199451e+00]],\n",
       " \n",
       "        [[-2.03288318e+00, -1.73229709e+00, -1.17717314e+00, ...,\n",
       "           1.95682493e+00,  1.42226669e+00,  4.85088282e-01],\n",
       "         [-2.40772297e+00, -2.18184540e+00, -1.63423270e+00, ...,\n",
       "           1.61391484e+00,  9.24117227e-01,  1.96482420e-01],\n",
       "         [-3.93168313e-02,  5.90748722e-01,  1.05528627e+00, ...,\n",
       "          -3.67882769e-01, -5.23203675e-01, -4.86380475e-01],\n",
       "         ...,\n",
       "         [-1.94691522e+00, -1.52073721e+00, -1.15900034e+00, ...,\n",
       "           1.93496349e+00,  1.69967195e+00,  2.15331090e-01],\n",
       "         [ 9.18174123e-01,  7.99186490e-01,  7.12279442e-01, ...,\n",
       "           6.83423921e-01,  9.83295547e-02, -4.08373688e-01],\n",
       "         [-1.21767670e-01,  3.27010088e-01,  5.14801205e-01, ...,\n",
       "           9.64843088e-02,  1.24665680e-01, -4.44229181e-02]]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sio.loadmat('OCD_90_200_fMRI.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有加伪样本的时候有20个正样本，有62个负样本，一共有82个样本\n",
      "(20, 90, 200) (62, 90, 200) (82, 90, 200) (20,) 62 20 8100\n"
     ]
    }
   ],
   "source": [
    "x_positive = data['NC']\n",
    "x_negative = data['OCD']\n",
    "# x_fake_positive = data['EMCI']\n",
    "# x_fake_negative = data['LMCI']\n",
    "x_total = np.concatenate((x_positive, x_negative), axis=0).astype(np.float)\n",
    "y_positive = np.ones(x_positive.shape[0])\n",
    "# y_fake_positive = np.ones(x_fake_positive.shape[0])\n",
    "# y_fake_negative = np.zeros(x_negative.shape[0])\n",
    "y_negative = np.zeros(x_negative.shape[0])\n",
    "y_total = np.concatenate((y_positive, y_negative), axis=0).astype(np.float)\n",
    "print('没有加伪样本的时候有{}个正样本，有{}个负样本，一共有{}个样本'.format(y_positive.shape[0], y_negative.shape[0], x_total.shape[0]))\n",
    "num_x_pos = x_positive.shape[0]\n",
    "num_x_neg = x_negative.shape[0]\n",
    "dim_input = np.prod(x_positive.shape[1]**2)\n",
    "# num_x_fake_pos = x_fake_positive.shape[0]\n",
    "# num_x_fake_neg = x_fake_negative.shape[0]\n",
    "# x_total_faked = np.concatenate((x_positive, x_fake_positive, x_fake_negative, x_negative), axis=0).astype(np.float)\n",
    "# y_total_faked = np.concatenate((y_positive, y_fake_positive, y_fake_negative, y_negative), axis=0).astype(np.float)\n",
    "# num_fake_total = x_total_faked.shape[0]\n",
    "num_total = x_total.shape[0]\n",
    "# print('加了伪样本之后有{}个正样本，有{}个负样本，一共有{}个样本'.format(num_x_fake_pos+num_x_pos, num_x_fake_neg+num_x_neg, num_fake_total))\n",
    "print(x_positive.shape, x_negative.shape, x_total.shape, y_positive.shape, num_x_neg, num_x_pos, dim_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_total_faked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用TSNE和PCA的可视化，发现几乎不具有线性可分性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 2)\n"
     ]
    }
   ],
   "source": [
    "x_tsne = TSNE(n_components=2).fit_transform(x_total.reshape(num_total, -1))\n",
    "print(x_tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e9ed19c4c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_tsne[:, 0], x_tsne[:, 1], c = list(y_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 2)\n"
     ]
    }
   ],
   "source": [
    "x_pca = PCA(n_components=2).fit_transform(x_total.reshape(num_total, -1))\n",
    "print(x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e9ed290b48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD5CAYAAADP2jUWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmnElEQVR4nO3deXxU1f3/8ddnZjJZ2QmIgIKKImpFjFupK1pRqViXorVuRbG/al1K3eq3WmsXrW2t1tblW1ulXyviUqVKtZYqrVXRqKgVNxAtoEDYIcusn98fc6EJmbBlkkky7+fjkUfmnnPm3s/NzeMzd8699xxzd0REpLCE8h2AiIi0PyV/EZECpOQvIlKAlPxFRAqQkr+ISAFS8hcRKUCRXK3IzMJANbDY3ceZ2VBgKtAHeA04y93jZlYMTAH2B1YAE9z9482tu2/fvj5kyJBchSoiUhBee+215e5ema0uZ8kfuBR4F+geLN8M3OruU83sLmAicGfwe5W772ZmpwftJmxuxUOGDKG6ujqHoYqIdH1m9klLdTnp9jGzQcAJwG+DZQOOAh4JmtwPnBS8Hh8sE9SPCdqLiEg7yVWf/y+BK4F0sNwHWO3uyWB5ETAweD0QWAgQ1K8J2ouISDtpdfI3s3HAMnd/LQfxNF7vJDOrNrPqmpqaXK5aRKTg5eLMfzRwopl9TOYC71HAbUBPM9twTWEQsDh4vRgYDBDU9yBz4bcJd7/H3avcvaqyMuv1ChER2U6tTv7ufo27D3L3IcDpwN/d/UzgOeDUoNk5wBPB6+nBMkH9370LjC63atka3vrHXJYtXJ7vUEREtiiXd/ts6ipgqpn9EHgDuDcovxf4g5nNA1aS+cDotFKpFL+66Lf89f5ZREuKSMQSVB07ku/+8VKKS4vzHZ6ISFbWGU66q6qqvKPe6jntlieYcsM0YnXxjWXRkiKOPvtwLr/rwjxGJiKFzsxec/eqbHV6wreVHrt9RpPEDxBvSPC3KbNIJVN5ikpEZPOU/Fupdk1d1vJkIkUinsxaJyKSb0r+rbTPF/Yk2yNqA4cNoKRMff4i0jEp+bfShT8/m9KKUiJFYQBC4RAlZcVceucFeY5MRKRlbXm3T0HYec9B3PPWz5n2s+m8N/tDhuw1mNO+cyJD9hqc79BERFqk5J8D/Xeu5Fu/mpjvMEREtpq6fURECpCSv4hIAVLyFxEpQEr+IiIFSMlfRKQAKfmLiBQgJX8RkQKk5C8iUoCU/EVECpCSv4hIAVLyFxEpQEr+IiIFSMlfRKQAKfmLiBQgJX8RkQKk5C8iUoCU/EVECpCSv4hIAVLyFxEpQEr+IiIFSMlfRKQAKfmLiBQgJX8RkQKk5C8iUoCU/EVEClCrk7+ZlZjZK2b2ppm9Y2Y3BOVDzWy2mc0zs4fMLBqUFwfL84L6Ia2NQUREtk0uzvxjwFHuvi8wEhhrZgcDNwO3uvtuwCpgYtB+IrAqKL81aCciIu2o1cnfM9YHi0XBjwNHAY8E5fcDJwWvxwfLBPVjzMxaG4eIiGy9nPT5m1nYzOYAy4BngfnAandPBk0WAQOD1wOBhQBB/RqgTy7iEBGRrZOT5O/uKXcfCQwCDgSGt3adZjbJzKrNrLqmpqa1qxMRkUZyerePu68GngMOAXqaWSSoGgQsDl4vBgYDBPU9gBVZ1nWPu1e5e1VlZWUuwxQRKXi5uNun0sx6Bq9LgWOAd8l8CJwaNDsHeCJ4PT1YJqj/u7t7a+MQEZGtF9lyky0aANxvZmEyHybT3P1JM5sLTDWzHwJvAPcG7e8F/mBm84CVwOk5iEFERLZBq5O/u78F7Jel/CMy/f+bljcAp7V2uyIisv30hK+ISAFS8hcRKUBK/iIiBUjJX0SkACn5i4gUICV/EZECpOQvIlKAlPxFRAqQkr+ISAFS8hcRKUBK/iIiBUjJX0SkAOViVE/JE098gDfMAFJYyVisaK98hyQinYSSfyeVXn8PrL8DSACO196Pl51DqPvkfIcmIp2Aun06IU/+B9b/CmgAUkA687rufjzxfn6DE5FOQcm/M4o9B2Sb/CyBNzzb3tGISCek5N8ZWYTsh86COhGRzVPy74yKjyH7mX8YKzmuvaMRkU5Iyb8TsnA/6H4jUAyUAiWZ192uwiI75zc4EekU1EfQSYXKTsKLvwCxmUAaio/EwjvkOywR6SSU/DsxC/eFsgn5DkNEOiF1+4iIFCAlfxGRAqTkLyJSgJT8RUQKkJK/iEgBUvIXESlASv4iIgVIyV9EpAAp+YuIFCA94dtGPL0OX/9raJgBRKDsFKz8Asyi+Q5NRKT1Z/5mNtjMnjOzuWb2jpldGpT3NrNnzezD4HevoNzM7HYzm2dmb5nZqNbG0NG4x/EVp0HdHyC9BNKLYP1d+KoLcM82GqeISPvKRbdPEpjs7iOAg4GLzGwEcDUw092HATODZYDjgGHBzyTgzhzE0LE0/BVSS8hMsbhBDOJzIPFmnoISEfmvVid/d//M3V8PXq8D3gUGAuOB+4Nm9wMnBa/HA1M842Wgp5kNaG0cHYnH5wB1WWrSkHirnaMREWkupxd8zWwIsB8wG+jv7p8FVUuA/sHrgcDCRm9bFJR1HZHBZMbY34RFINy1dlVEOqecJX8zqwAeBS5z97WN6zzT0b1Nnd1mNsnMqs2suqamJldhtgsrHZ9lOsUQWAUUH5aXmEREGstJ8jezIjKJ/wF3fywoXrqhOyf4vSwoXwwMbvT2QUFZE+5+j7tXuXtVZWVlLsJsNxbqifX+PwgPA6JAERTti/V+kMyfSkQkv1p9q6eZGXAv8K67/6JR1XTgHOCm4PcTjcovNrOpwEHAmkbdQ12GFY3AKp/CU8vBwlioV75DEhHZKBf3+Y8GzgLeNrM5Qdl3yST9aWY2EfgE+EpQNwM4HphH5qroeTmIocOycN98hyAi0kyrk7+7vwBYC9VjsrR34KLWbldERLafhncQESlASv4iIgVIyV9EpAAp+YuIFCAlfxGRAqTkLyJSgJT8RUQKkCZz6cA8vR6vm5IZIjrUAys7Cys5uk22tWb5WurW1dN/50pCIZ0TiHR1Sv4dlKfr8BWnQOpTIJYpi8/By88j1O2ynG1ndc0afnLm7bz9z7mEwiEqepQz+d7/xwFj98vZNkSk49EpXgfl9Y9C6jM2JP6Meqi9F0+tyM023Llm7I948/l3SMSSxOrirPhsFTec+jM+mbtwyysQkU5Lyb+jij0PNDQvtyJIzMnJJua/+TGLPviUVDLVpDwRS/L4r/6Sk22ISMek5N9RhXcg++FJQ6hPTjaxYvFKwpHm20in0nz60dKcbENEOiYl/w7Kys4kMxdAYyEIVULRvjnZxq77DSURSzYrj5ZG2e/IvXOyDRHpmJT8OygrGgE9fgxWnpkBjBKIDMN630dmCoXW67tjb8ZOPIqS8uKNZZGiMBU9yznhwmNysg0R6Zh0t08HFiodh5d8ERLvQqgbFtkl59u4+PaJ7DZyKH+6fQa1a+o4+EtVfO1/TqFbr4qcb0tEOg7LDK/fsVVVVXl1dXW+w9gid4fkB+ANULQnZpt224iItB8ze83dq7LV6cw/Rzw5H191IaRryPSmhaDHzW32UJaISGuozz8H3JP4yrMhtRC8HrwWfB2++tt48pN8hyci0oySfy7EXwKvAzbtQkvi9Q/lIyIRkc1S8s+F9AqaJ36AJKSWtXc0IiJbpOSfC9EDwFNZKsqw4sPbPRwRkS1R8s8BCw+EsglgpY1KSyAyFEqOzVtcIiIt0d0+OWLdroXoAXjdA5Cug9JxWNnput1TRDokJf8cMTMoORbTmb6IdAJdNvmvWb6Wx+/4C2/MfJsdhvTjlMvHMWxU7p+QFRHpjLpk8l+5ZBXf2O8KatfUEW9IMPelD3jhT7O5asolHHryQfkOT0Qk77rkBd8HfvQYa1euJ96QAMDTTqwuzm3fuJtUKttdOSIihaVLJv9XnnqdVKJ5ko/Vx/lsvsapFxHpksm/W5/sI1KmkmnKe5a3czQiIh1Pl0z+p377S03GqIfMOPX7HLonvfr1yFNUIiIdR5dM/keePpqTvnUc0ZIiynuUUVwWZdj+u3Ltg5flOzQRkQ4hJ+P5m9nvgHHAMnffOyjrDTwEDAE+Br7i7qssMw3VbcDxQB1wrru/vrn1b+94/mtXrGPenI/pO7A3Ow0fuM3vFxHpzDY3nn+uzvzvA8ZuUnY1MNPdhwEzg2WA44Bhwc8k4M4cxdBM9z7dGDVmHyV+EZFN5CT5u/s/gJWbFI8H7g9e3w+c1Kh8ime8DPQ0swG5iENERLZOW/b593f3z4LXS4D+weuBwMJG7RYFZU2Y2SQzqzaz6pqamjYMU0Sk8LTLBV/PXFjYposL7n6Pu1e5e1VlZWUbRSYiUpjaMvkv3dCdE/zeMKvJYmBwo3aDgjIREWknbZn8pwPnBK/PAZ5oVH62ZRwMrGnUPSQiIu0gJwO7mdmDwBFAXzNbBFwP3ARMM7OJwCfAV4LmM8jc5jmPzK2e5+UiBhER2Xo5Sf7ufkYLVWOytHXgolxsV0REtk+XfMJXREQ2T8lfRKQAKfmLiBQgJX8RkQKk5C8iUoC65By++TDvjQVU//VNyrqVcthpB9OzUvMGiEjHpeTfSu7OrZPu5u8P/pNkPEUkGuaeK6dw/SPf4YCx++U7PBGRrNTt00qvzHid56a+QKwuTiqZIlYXJ1YX58YJvyDeEM/6nkQ8wZzn/s2bz79DIp5o54hFRHTm32rPTplFQ22sWbmZ8ebz7zQ7+3/9b2/xg9N+zoZJdEKhEN97eDKjxuzTLvGKiIDO/FttczOhbVq1Zvlarv/yT6ldU0fd2nrq1tazfnUt1590M2tXrGvjSEVE/kvJv5WOPuvwZpPFA3ja2feIEU3Knn/oRTzd/MPC3Zk17cU2i1FEZFPq9mmlg8ftz6GnHMw/HnmZREOcSHERBlz74GUUlzb9UFi/upZErHkffyKWZN2q2naKWEQ6OnfnrVlzeXbK86RSaY464wtUHTuSzBTouaHk30pmxpX3Xcz4i8ZS/cyblHUv5YgJn6dX/57N2o46+nNMvelPza4RFBUXsf8X9wUyBz2XB1hEOp+7r5jCU3c/S6wuhju88NhsDj/tECbf+82c5QfbXJ91R1FVVeXV1dX5DmO7bUjo7s6Pz7yNl/9cvfEDoKS8mINOGEX33t3465RZxBvi7POFPfnWr89nyF6Dt7BmEelqPnl3Ed+suop4fdO7BYvLirll5vXsedCwrV6Xmb3m7lXZ6tTn30bcU6TX3U566f740j1ILx8H8Ve45v8u4YrfX8SBx4/ioBNGceV9F7Nm+Tqe/v1zmU/5tPP2P+dy6ehrWfHZqnzvhoi0s+qn5+DpdLPyeH2c2U+9lrPtqNunjfjaH0L9o0BDpiD5Ab7qAqzPgxx26iEcduohAHz8zkLeffmDJtcC3DPXAf58118594YJeYheRPKltKKEcCRMIpZsUh4pClPWrTRn29GZfxvw9Dqof5iNiX+jGL7+N01KFr63mHAk3GwdiViCeW8saLsgRaRD+sLJBzW7TRzAwiGOmPD5nG1Hyb8tpD4FK8pS4ZD8oEnJTnsOJJlINWsZLSli9/13aaMARaSj6t6nG9c9PJmS8mLKupdS1r2U4tIoV/zum/TbqTJn21G3T1sIDwRPZqkwiAzfuLT0kxqee+hFuvUqZ3UyRSr4EDCDopIivvSNLwLg6bWQ+g+Ed8RCvdtjD0Qkjw48bj+mLfktb/ztbVKpNKOO3ofy7mU53YaSfxuwUAVedgbUPQTUN66BkmMAeOa+5/jFpLvwVBp3sLBhZljI+NzhI/jWHefTs1930mt/AnV/zHyT8DhechzW40eYRfOybyLSPkrLS/j8+APabP1K/m3Eul2NUwR1vwUcd/jkgygNtT+k3lbws6/PaNLeU5lOvkgkzPw5H1O/rh6vmwJ1U4EYeIx0Gj58eRapyPfZ84gbs14rEBHZGkr+bcQshKeXA8biBUVcd/ZQaj4twgwa6p8Csj+okYglScTWc81xP2Lqm/OJhDPfHN57o5QbzhtKfW0Is/cIF03k2qmXs/8x+7bfTolIl6ELvm0p/i/S6TRXnbYri+YXE6sP01AXBt/yE3qpZIo5/8w85FFfG+Ka03dl5bIi6mvD1K0Ps25VLdd/+RZWLtGzACKy7ZT821KoJ2+/XM7aVWFaOtNvkUN9LHO3z4tPdyfLMx+kU2lmPvDP1scpIgVHyb8NWflE1qwoIxnf9rE4kokkI4/9NlgZa1dFs64jEUuwaumaXIQqIgVGyb8tlZzE8NHHk0q1nPzDRWEwCIUzbUIho7g0ygU3f40eO1RhfR4jXLI3yUTzdRSXFTPq6M+1Wfgi0nXpgm8bMjPuvbGMzXX5HHrywZx74wTmz/mYfz46m/IeZRx3/hj2qNo10yA8lIduJ+s6ynuUMepozQAmIttOyb+NeGop77/wS16a/iEtJf9wUZgjzxjNwN0GMHC3ARvH+2lsxWerWLt8bdb3p1IpQiF9eRORbafk3wY8tQRffiJvziwmmehHS8m/78DeHHT8qM2uq6xbadbZvwC6965obagiUqB02tgGfP1d4Gvp1jNBUTR74h4yooLbnhtPKGzUrq3jt999gP+3/5XcOOEXfPrRko3tSqNzOGDMGiLRprf7lJQVc+rlX2rT/RCRrkvJfzu5O9PvfIav7vwNTij7Kpd8/rvMfen9TGX8BSDNoeNW41lu0QTnsHEf0avkKmreOZGvDDifh256nHlvLOAfD7/EOcO+xayHX8TTq/DV3+A7t37EXlW1FJekKeuWoqg4zdiJoznu/DHtuMci0pXkbSYvMxsL3AaEgd+6+00tte2IM3n94QcPM+2nT9BQ998pGYvLotz6jxvZdeer+c/cd3nkzkqef6InsfrmwzBES9IM26eOBe+WULe+ee9bJGpMX3Ysc/7yv7z5ryg9K5MM36+WWH2YoXs60T6XsnLNMfTfuW+zuYJFRGDzM3nlJfmbWRj4ADgGWAS8Cpzh7nOzte9oyT9WH+OUyonE6prOxWsGB52wP6d/ZzBXH/co8biRTrX05crZ/INfzh4jY3zyQRENdSGixU4o7Fx37wL+8edezHy0kkg0SjrlnHH1SXz12lM096+INLG55J+vC74HAvPc/SMAM5sKjAeyJv+OpmbRSkKh5onWHebP+Zg7Ll9JQ5az/aa2nKjnz42SjGc+POKxTPvvn7sLZpCIpUnEMpPFTL3pcfrs2JuxXz9q23ZERApWvvr8BwILGy0vCso2MrNJZlZtZtU1NTXtGtyW9BnQk1Qya2c+A3cfwPw5H29hDVvxbcvYmPgbi8eMWEPT8oa6GFNv+tOW1ykiEuiwF3zd/R53r3L3qsrK3M1ekwulFaWccOHRFJc1HVO/uDTKWded1qy8uWxn/b7xt5mz07D6LG1aei+sWqZhHkRk6+Ur+S8GBjdaHhSUdRoX/uxsTvn2lyjtVkIoZAzYpT/fm/ZtPnfYCE6YdAzFpds22YqFAJxw2AlHnF6VqWa3d0LmukI2ww8ctu07ISIFK18XfCNkLviOIZP0XwW+6u7vZGvf0S74NubuJOJJosX/nbM3EU/w03Pu4F+Pv0q0pIi6dfUtPqi1QbgoRCrRONlvekE48/5wBNIp2zjBswVjAd36jxvZbb+hudkpEekSOtwFX3dPmtnFwDNkbvX8XUuJv6MzsyaJH6AoWsS1D17O8k9X8tn8pdQsWs5Pzrx9s+tpmvihefdOZjmVBHAsGNahtLyEUy4fx64jh2z3PohI4cnb8A7uPgOYscWGnVjfHXvTd8fefPj6R5ncnbMvWbbxm0Tdunqm/Ww6q5ev5ZI7zs/VBkSki+uwF3y7kk/mLmr27SCXYnUxnr737yz/dGWbbUNEuhYl/3YwePhAQuG2/VMXFUe24hZTEZEMJf8tqF1bx12T72fCwAs4Y/CF/O7aPzYZ0mFr7L7/Luyy785Eoi33snXv27oROlPJNP0G92nVOkSkcCj5b0YqmeLS0f/D9N88zcrPVrN88UoeufVJrhhzA1t7l5SnPoP4C/zkyXM55uzDW2yXTqUzs3plkXluYDPbMxiy1yCG7rPzVsUkIqLkvxkvTq9m2Sc1JGLJjWWJhgSfvLOQOc/9e7PvdU+QXj0Zr/kivvoyShpO5pvff5WW5l5Zv6qOHYdWUNTo3v5INMWY01az/xHxzY4GYcAlv7lgW3ZNRAqckv9mfPDafOrXNzQrj8cSzHt9wWbf6+vvgoZngRj4OiBGNPQKA4a03GW06MPVwf37DjjJeIhZj3fn5WccvOXs7w4fvvbRVu2TiAgUaPJ3963qthkwtD8l5c2HS46WFNFv5y0MOVH3ALDpB0eMi3+8iKLiNNm6cdwhmQiROZfP/CQTIdKpLYbKrEde2nIjEZFAQSV/9wbSa2/El47Elw4nveJ0PPFeC22dil7lJOLJJuWhkFFaXsIhJ2Z9aK7RCuqyFo86bD0Tv7uEUDjbh09LZ/dbHgF0yUdLt9hGRGSDwkr+qy6GumlAPeCQeB1feUbmouwm/veq/+OWc+8glWh02m0w/KBh/PJfP9zyffvRA8matMPDOHpCEZHterwu+7cVCxnD9t91e1YoIgWqYJK/Jz+G+CvAJn3uHsdrpzQpWvpJDU/c8Rcaapu2LSkr5tTJJzJgaP8tbs+6XwNWAWz4kIiAlWI9fkz3YU9zxlX7bsdeZP8GsGE0URGRrVUwyZ/kArBsp9sJSL7bpOTN598hHGl+22VDbYzZT27dAHMW2RXr+xSUnwNFB0Dp6VifP2PRfTErYdiB4ygp277pF8NFYbr1qaCkooSRR+3NL2b9gCF7Dd7yG0VEAnkb26fdRXYFT2SpiELRXk1KKnqVZ50SMRwJ07Nfj63epIV3wLpdmbUuWlJEKLJ9n71FxUVceMvZHHvukdv1fhGRgkn+FtkJLx4NsRf57104BhbFys5q0rbq2JFZH7iKFIVzNlXiPofuSaSFh7oaM7NmdyZ52hl90oE5iWNbvTv7Qx7++XSWLFjGyCP35tRvj6P3Dr3yEouIbL/C6fYBrOftUHYmWDcgAtGDsN4PYeEdmrSLFhfx079dR58de1HarYSy7qWUVJRwxe8vYtDuO+YklkhRhB8++V3Ke5RR1q2UkvJizIxIURgzo6SihO59Kvj6T75KcWmUsm6llHUrpbSihO8/dgUVPctzEse2mPXwS1wx5vu88OjLfPjaRzx++wwu2GcyNYtWtHssItI6eZnMZVvlazKXdDrNe7M/JFYfZ8Qhu1Ncun199JsTb4gze8Yb1K6pY+RRe7HwvU/54NX59NupL1845SAWvP0f7vr2fcx7YwEVvSo4+/rTOGHSMVm7pdpSKpXiKztcwNoV65qUhyNhjj3vSC6/+8J2jUdEtqzDTebSWYRCIUYcskebbqOouIg9qnYhXBShz4Be7LBzPw44diSQecL4yqNvIFYXB2DVktXcPXkKtWvrmXDF+DaNa1NLFiwj3hBvVp5Kpqj+65x2jUVEWq9gun3WrljHv194l2ULl+c7lI3er57PeXtcwnnDL+WsXS7iogOu4tP5SzbW3/e9qRsT/wYNdTEeuPEREvFsF6/bTrdeFaSS2R817lnZvV1jEZHW6/LJ392569v3ccbgC/mfL93EeXtcwvfG37zNwzLn2prla7lyzA0snreEeEOCRCzBh28s4PLDriOZyDxV3NL4/O7Oik9XtWO00L1PN0Yd/blmw1KXlBdz2uQT2zUWEWm9Lp/8p9/5DE/e8zfiDQlq19QRb0jw+rNvcvtF/5vXuJ6dMovkJmfSnnYa1jfwyow3ANhxtx2yvRVP+zbdcporV//hEvYePZxoaZSy7qVES4o4dfKXOPwrn2/3WESkdbp8n/+jv3iS2CZn+fGGBM9PfZHL7pxEtCSal7iWflJDvL55H3oykdx498xZ13+F68bf1KTrp7ismHEXHr3dD4i1RkXPcm6ZeT2fLVjKik9XMXTvwZT3aP+7jkSk9br8mf+6Veuzlrt7Xrt+9h49nNKKkmbloXCI4QcNA2DUmH24asolVA7uQygSorSihJMvO56JN32N2jW1pFJbMdxnGxgwtD97jx6uxC/SiXX55P+5w0ZkvS2y74696dardVMntsYh46uaDRddVBxhn0NHsEfVfwdpO/Tkg3jg4zt5fNX9/GnVffTfuZLTB07i1H4TObnPeTx405+2elYxEZENunzyv+Dmr1HWvXTj07QWMorLolxy5wXtcq+8ezxrcv79tQ9St7a+adu0c94PJzRra5YZRnrWtJe48/L7Wbt8HclEirq19Tzww0eZdssTbRa/iHRNXT75D9p9R+5582eccOExDBs1lCMmjOa2f/1o4730bcUbniNdMwZf+jl82SjS627DPdNNU7u2jum/eYbYJn3+qVSaqTe3nMinXP9Qs+sXsboYU296XGf/IrJNuvwFX4B+O1Vy8e0T2217Hn8VX30pG8cQ8lqo/R3udVj3a1j6cQ2RaIR4Q9N79T3tzHuj5ekhaxatzFpet66eeEO8TZ5AFpGuqcuf+eeDr7+D5lM41kPdH/F0Hf126ttkUvgNzGDI8BK84a94el2z+p32HJh1e73698jbXUsi0jkp+beFZAuTqVsY0sup6FnOsecdSXFZ04QdLUlz3Okv8ugtP2HqdeP4qPr3Teov+OlZFJc2fU9xWZTzb/5au4/1IyKdmwZ2awPplZMgPotm0y5aKdbvFcyKSSVTTLnhYR7/1Qzq1taz8x4xDvniah67p5K0QzoFoTB8+VtHMumWizeu4o2/v8293/0j/5m7iP5D+nHuDybkbXhnEenYNjewm5J/G/DEv/EVZ5KZK3iDUqi4gFDFxU3bupOq/TPrF97AmfsPId7Q/MvYF889gvN/cia9+vds07hFpGvZXPJXt08bsKK9sd6/h6J9gSiEBkC3q7Dyi5q3NSMcqueVmaWEQtk/iP963/OcOeSbTL/zmTaOXEQKhZJ/G7HoKEJ9Hia0w78J9ZtFqPyrLffLR0dnvgEkW+63T8QS3D15CgvfX9xGEYtIIWlV8jez08zsHTNLm1nVJnXXmNk8M3vfzI5tVD42KJtnZle3ZvtdhUUGcdCJJ5FKbf6ibSqZ4rkH/9VOUYlIV9baM/9/AycD/2hcaGYjgNOBvYCxwG/MLGxmYeDXwHHACOCMoG3B67nzFXxl8sGbbZNOpYnV53coahHpGlqV/N39XXd/P0vVeGCqu8fcfQEwDzgw+Jnn7h+5exyYGrQV4Os/mcy+R+5FuCj7YYmWRhn95YPaOSoR6Yraqs9/ILCw0fKioKyl8mbMbJKZVZtZdU1NTRuF2bGYGTc/8z0uu+sb9B9SiYUMs0x5SVkxx5x9OCMO3j3fYYpIF7DF4R3M7G9AtllFrnX3NhtRzN3vAe6BzK2ebbWdjiYcCTP2vCMZe96RzJuzgJkP/JNkPMnhpx3CXqOHb2z30pOv8csL72LVkjVEohEOOmEUfQf2JhKNMObMQ9lt5NA87oWIdHRbTP7ufvR2rHcxMLjR8qCgjM2UyyZ2Gzk0axKvfmYO151408blRCzBC4/NBiAUMv78m2c46/rTmHDlSe0Vqoh0Mm3V7TMdON3Mis1sKDAMeAV4FRhmZkPNLErmovD0Noqhy7rtmy1PQZlOO7H6OFO+P61DTVYvIh1La2/1/LKZLQIOAZ4ys2cA3P0dYBowF3gauMjdU+6eBC4GngHeBaYFbWUb1CxcscU2Zsbsp15vh2hEpDNq1ZDO7v4n4E8t1P0I+FGW8hnAjNZst9CVdith/arazbaxkFFUXNROEYlIZ6MnfDuhr33v1C228bTz+fFZh/QQEVHy74xOuWwc4y8e22y4iOKyKKUVJRSXRrnmgUvp3rtbniIUkY5Oo3p2Yslkko/e+g/9dupLOpnilb/MIVIU5uBx+1PRszzf4YlInm1uVM+CmMaxq4pEIuw+apeNy2PPOzKP0YhIZ6JuHxGRAqTkLyJSgJT8RUQKkJK/iEgBUvIXESlAneJWTzOrAT7JdxztrC9QiIPzaL8Li/a7be3s7pXZKjpF8i9EZlbd0v25XZn2u7Bov/NH3T4iIgVIyV9EpAAp+Xdc9+Q7gDzRfhcW7XeeqM9fRKQA6cxfRKQAKfl3MGY21szeN7N5ZnZ1vuPJJTMbbGbPmdlcM3vHzC4Nynub2bNm9mHwu1dQbmZ2e/C3eMvMRuV3D1rHzMJm9oaZPRksDzWz2cH+PRRMbUow/elDQflsMxuS18Bbwcx6mtkjZvaemb1rZocUwvE2s8uD//F/m9mDZlbS0Y63kn8HYmZh4NfAccAI4AwzG5HfqHIqCUx29xHAwcBFwf5dDcx092HAzGAZMn+HYcHPJODO9g85py4lM33pBjcDt7r7bsAqYGJQPhFYFZTfGrTrrG4Dnnb34cC+ZPa/Sx9vMxsIXAJUufveQJjMfOUd63i7u346yA+ZuZCfabR8DXBNvuNqw/19AjgGeB8YEJQNAN4PXt8NnNGo/cZ2ne0HGEQm0R0FPAkYmYd8IpseezJzXB8SvI4E7Szf+7Ad+9wDWLBp7F39eAMDgYVA7+D4PQkc29GOt878O5YN/zQbLArKupzgq+1+wGygv7t/FlQtAfoHr7vS3+OXwJVAOljuA6x292Sw3HjfNu53UL8maN/ZDAVqgN8H3V2/NbNyuvjxdvfFwM+A/wCfkTl+r9HBjreSv7Q7M6sAHgUuc/e1jes8c/rTpW5BM7NxwDJ3fy3fsbSzCDAKuNPd9wNq+W8XD9Blj3cvYDyZD78dgXJgbF6DykLJv2NZDAxutDwoKOsyzKyITOJ/wN0fC4qXmtmAoH4AsCwo7yp/j9HAiWb2MTCVTNfPbUBPM9swm17jfdu430F9D2BFewacI4uARe4+O1h+hMyHQVc/3kcDC9y9xt0TwGNk/gc61PFW8u9YXgWGBXcFRMlcJJqe55hyxjIzzt8LvOvuv2hUNR04J3h9DplrARvKzw7uAjkYWNOou6DTcPdr3H2Quw8hc0z/7u5nAs8BpwbNNt3vDX+PU4P2ne7s2N2XAAvNbI+gaAwwly5+vMl09xxsZmXB//yG/e5YxzvfF0f00+xi0fHAB8B84Np8x5PjffsCma/4bwFzgp/jyfRvzgQ+BP4G9A7aG5m7n+YDb5O5eyLv+9HKv8ERwJPB612AV4B5wMNAcVBeEizPC+p3yXfcrdjfkUB1cMwfB3oVwvEGbgDeA/4N/AEo7mjHW0/4iogUIHX7iIgUICV/EZECpOQvIlKAlPxFRAqQkr+ISAFS8hcRKUBK/iIiBUjJX0SkAP1/+GIymWiFdVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_pca[:, 0], x_pca[:, 1], c = list(y_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理（划分train/test dataset和载入dataloader）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理第一步，计算相关系数，并flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 4005)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def corrcoef(input):\n",
    "    \"\"\"传入一个tensor格式的矩阵x(x.shape(m,n))，输出其相关系数矩阵\"\"\"\n",
    "    output = []\n",
    "    for index, x in enumerate(input):\n",
    "        f = (x.shape[0] - 1) / x.shape[0]      # 方差调整系数\n",
    "        x_reducemean = x - np.mean(x, axis=0)\n",
    "        numerator = np.matmul(x_reducemean.T, x_reducemean) / x.shape[0]\n",
    "        var_ = x.var(axis=0).reshape(x.shape[1], 1)\n",
    "        denominator = np.sqrt(np.matmul(var_, var_.T)) * f\n",
    "        output.append(numerator / denominator)\n",
    "    return output\n",
    "# print(x_total[:, :, 19:179].shape)\n",
    "pearson = corrcoef(x_total[:, :, 20:180].reshape(82, 160, 90))\n",
    "pearson = np.array(pearson)\n",
    "pearson_cutted = np.zeros((82, 45*89))\n",
    "dim_pearson = 90\n",
    "t = 0\n",
    "for k in range(pearson.shape[0]):\n",
    "    for i in range(dim_pearson):\n",
    "        for j in range(dim_pearson):\n",
    "            if i < j:\n",
    "                pearson_cutted[k, t] = pearson[k, i, j]\n",
    "                t = t + 1\n",
    "        \n",
    "    t = 0\n",
    "pearson_cutted = np.array(pearson_cutted)\n",
    "print(pearson_cutted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理第二步，划分t/t dataset和载入dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "################# batch_size也是一个超参数，第一个调整的参数就是batch_size,可选：1，2，4，8，16，32。\n",
    "batch_size = 1\n",
    "kfold = 10\n",
    "dim_input = 4005\n",
    "\n",
    "meta_size = int(0.1*x_total.shape[0])\n",
    "# train_size = int(0.8*x_total.shape[0])\n",
    "# test_size = int(0.9*x_total.shape[0])\n",
    "x_total = pearson_cutted\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_val = []\n",
    "# y_val = []\n",
    "# x_test = []\n",
    "# y_test = []\n",
    "# for i in range(kfold):\n",
    "#     x_train.append(mixed[meta_size * i: meta_size * (i+1), :dim_input])\n",
    "    \n",
    "\n",
    "# x_total = pearson_cutted\n",
    "# mixed = np.concatenate((x_total, y_total.reshape((-1, 1))), axis = 1)\n",
    "# random.shuffle(mixed)\n",
    "\n",
    "\n",
    "# print(mixed)\n",
    "# x_train = mixed[:train_size, :dim_input]\n",
    "# y_train = mixed[:train_size, dim_input:]\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# x_val = mixed[train_size:test_size, :dim_input]\n",
    "# y_val = mixed[train_size:test_size, dim_input:]\n",
    "# print(x_val.shape, y_val.shape)\n",
    "# x_test = mixed[test_size:, :dim_input]\n",
    "# y_test = mixed[test_size:, dim_input:]\n",
    "# print(x_test.shape, y_test.shape)\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Normalize(0.5, 0.5)\n",
    "# ])\n",
    "# train_data = Data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "# # print(train_data[0][0].dtype)\n",
    "# val_data = Data.TensorDataset(torch.Tensor(x_val), torch.Tensor(y_val))\n",
    "# test_data = Data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "# train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# val_loader = Data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# test_loader = Data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# total_loader = Data.DataLoader(dataset = Data.TensorDataset(torch.Tensor(mixed[:,:dim_input]), torch.Tensor(mixed[:, dim_input:])), batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面只需要用train_loader作为迭代器，用x_val,y_val（迭代器val_loader）来调参，当在x_val和y_val上达到最优的时候，在x_test(test_loader)上测试一次，作为一个算法的最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### 用于eval，非必要不改动\n",
    "# ########### 敏感性即召回率，true positive rate = TP/(TP+FN)\n",
    "# ########### 特异度为true negative rate = TN/(FP+TN)\n",
    "# def evaluate_accuracy(loader, net):\n",
    "#     net.eval()\n",
    "#     sum_all = 0\n",
    "#     sum_acc = 0\n",
    "#     FN = 0\n",
    "#     TN = 0\n",
    "#     TP = 0\n",
    "#     FP = 0\n",
    "    \n",
    "#     for index, (data, label) in enumerate(loader):\n",
    "#         with torch.no_grad():\n",
    "#             data = Variable(data, requires_grad=True).to(device)\n",
    "#             label = Variable(label, requires_grad=True).to(device)\n",
    "#         outputs = (net(data) > 0.5).type(torch.float)\n",
    "# #         print(outputs.shape, label.shape)\n",
    "#         sum_acc += torch.sum(outputs.argmax(0) == label)\n",
    "#         for i in range(outputs.shape[0]):\n",
    "#             if outputs[i, 0] == label[i] and label[i] == 1:\n",
    "#                 TP += 1\n",
    "#             elif outputs[i, 0] == label[i] and label[i] == 0:\n",
    "#                 TN += 1\n",
    "#             elif outputs[i, 0] != label[i] and label[i] == 1:\n",
    "#                 FN += 1\n",
    "#             else:\n",
    "#                 FP += 1\n",
    "#         sum_all += data.shape[0]\n",
    "#     print('total validation set data:{}, numbers of accurately labeled data:{}'.format(sum_all, sum_acc.detach()))\n",
    "#     acc = sum_acc / sum_all\n",
    "#     net.train()\n",
    "#     if (TP + FN) == 0:\n",
    "#         sensitivity = 0\n",
    "#     else:\n",
    "#         sensitivity = TP / (TP + FN)\n",
    "#     if (FP + TN) == 0:\n",
    "#         specificity = 0\n",
    "#     else:\n",
    "#         specificity = TN / (FP + TN)\n",
    "#     return acc, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现算法一（传统方法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############在class里面定义自己的算法，xxxx是算法的名字。\n",
    "# class xxxx(nn.Module):\n",
    "#     def __init__(self, n_feature):\n",
    "#         super(xxxx, self).__init__()\n",
    "#         self.linear = nn.Linear(n_feature, 1)\n",
    "    \n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         \"\"\"Xavier initialization for the fully connected layer\n",
    "#         \"\"\"\n",
    "#         self.linear.weight.data.uniform_(-1, 1)\n",
    "#         self.linear.bias.data.fill_(0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         y = self.linear(x)\n",
    "#         return torch.sigmoid(y)\n",
    "    \n",
    "# # net = LinearNet(dim_input).to(device)\n",
    "# # print(net) # 使用print可以打印出网络的结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM的evaluate代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_svm(x_val, net):\n",
    "#     score = clf.score(x_val, y_val)\n",
    "#     pred = clf.predict(x_val)\n",
    "#     FN = 0\n",
    "#     TN = 0\n",
    "#     TP = 0\n",
    "#     FP = 0\n",
    "# #     sum_acc += np.sum(clf.predict(x_val) == y_val.reshape(x_val.shape[0]))\n",
    "#     for i in range(pred.shape[0]):\n",
    "#         if pred[i] == y_val[i, 0] and y_val[i, 0] == 1:\n",
    "#             TP += 1\n",
    "#         elif pred[i] == y_val[i, 0] and y_val[i, 0] == 0:\n",
    "#             TN += 1\n",
    "#         elif pred[i] != y_val[i, 0] and y_val[i, 0] == 1:\n",
    "#             FN += 1\n",
    "#         else:\n",
    "#             FP += 1\n",
    "#     if (TP + FN) == 0:\n",
    "#         sensitivity = 0\n",
    "#     else:\n",
    "#         sensitivity = TP / (TP + FN)\n",
    "#     if (FP + TN) == 0:\n",
    "#         specificity = 0\n",
    "#     else:\n",
    "#         specificity = TN / (FP + TN)\n",
    "        \n",
    "#     return score, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM训练过程代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# import sklearn.metrics as metrics\n",
    "# # var_list = [0.1, 0.5, 1, 1.5, 5, 10]\n",
    "# var_list = ['rbf','linear', 'poly', 'sigmoid']\n",
    "# for var in var_list:\n",
    "#     avg_sen = 0\n",
    "#     avg_spe = 0\n",
    "#     avg_score = 0\n",
    "#     roc_auc = dict()\n",
    "#     fpr = dict()\n",
    "#     tpr = dict()\n",
    "#     print('var of SVM:{}'.format(var))\n",
    "#     for j in range(100):\n",
    "#         random.seed(j+1)\n",
    "#         mixed = np.concatenate((x_total, y_total.reshape((-1, 1))), axis = 1)\n",
    "#         random.shuffle(mixed)\n",
    "#         kfold = 10\n",
    "#         GTlist = None\n",
    "#         Problist = None\n",
    "#     #     scores = []\n",
    "#     #     avg_score = 0\n",
    "#         for i in range(kfold):\n",
    "#             clf = SVC(kernel = var, probability = True)\n",
    "#             x_val = mixed[meta_size * i:meta_size*(i+1), :dim_input]\n",
    "#             y_val = mixed[meta_size * i:meta_size*(i+1), dim_input:]\n",
    "#             x_train = np.concatenate((mixed[:meta_size*i, :dim_input], mixed[meta_size*(i+1):, :dim_input]), axis=0)\n",
    "#             y_train = np.concatenate((mixed[:meta_size*i, dim_input:], mixed[meta_size*(i+1):, dim_input:]), axis=0)\n",
    "#             clf.fit(x_train, y_train)\n",
    "#         #     print('predict:{}, true:{}'.format(clf.predict(x_val), y_val))\n",
    "\n",
    "#             score, sen, spe = evaluate_svm(x_val, clf)\n",
    "#     #         score = clf.score(x_val, y_val)\n",
    "#     #         scores.append(score)\n",
    "#             avg_score += score\n",
    "#             avg_spe += spe\n",
    "#             avg_sen += sen\n",
    "#             if j is 1:\n",
    "#                 if GTlist is None:\n",
    "#                     GTlist = y_val\n",
    "#                 else:\n",
    "#                     GTlist = np.concatenate((GTlist, y_val), axis = 0)\n",
    "#                 if Problist is None:\n",
    "#                     Problist = clf.predict(x_val)\n",
    "#                 else:\n",
    "#                     Problist = np.concatenate((Problist, clf.predict_proba(x_val)[:, 1]), axis = 0)\n",
    "#         if j is 1:\n",
    "# #             print(GTlist.shape, Problist.shape)\n",
    "#             fpr, tpr, thresholds = metrics.roc_curve(GTlist.reshape(80), Problist, pos_label=1)\n",
    "# #             print(fpr.shape)\n",
    "#             roc_auc = metrics.auc(fpr, tpr)  #auc为Roc曲线下的面积\n",
    "#             print(roc_auc_score(GTlist, Problist))\n",
    "\n",
    "\n",
    "#             plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "#             plt.legend(loc='lower right')\n",
    "#             # plt.plot([0, 1], [0, 1], 'r--')\n",
    "#             plt.xlim([-0.1, 1.1])\n",
    "#             plt.ylim([-0.1, 1.1])\n",
    "#             plt.xlabel('False Positive Rate') #横坐标是fpr\n",
    "#             plt.ylabel('True Positive Rate')  #纵坐标是tpr\n",
    "#             plt.title('Receiver operating characteristic example')\n",
    "#             plt.savefig('roc_curve.png')\n",
    "#             plt.show()\n",
    "#     #         fpr, tpr, _ = roc_curve(y_val, clf.predict(x_val), pos_label=2)\n",
    "#     #         roc_auc = auc(fpr, tpr)\n",
    "#         #     print(scores)\n",
    "#     print('score:{}'.format(avg_score/(kfold * 100)))\n",
    "#     print('specificity:{}'.format(avg_spe/(kfold*100)))\n",
    "#     print('sensitivity:{}'.format(avg_sen/(kfold*100)))\n",
    "#     print(clf.predict(x_val), y_val)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.predict(x_val), np.sum(clf.predict(x_val) == y_val.reshape(x_val.shape[0])))\n",
    "# print(y_val[2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现算法二（传统方法/深度方法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############在class里面定义自己的算法，xxxx是算法的名字。\n",
    "# ### GAN based-methods\n",
    "# ########### 用于eval，非必要不改动\n",
    "# ########### 敏感性即召回率，true positive rate = TP/(TP+FN)\n",
    "# ########### 特异度为true negative rate = TN/(FP+TN)\n",
    "import torch.nn.functional as F\n",
    "def evaluate_accuracy(loader, net):\n",
    "    net.eval()\n",
    "    sum_all = 0\n",
    "    sum_acc = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    \n",
    "    for index, (data, label) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            data = Variable(data, requires_grad=False).to(device)\n",
    "            label = Variable(label, requires_grad=False).to(device)\n",
    "        outputs = net(data).argmax(1).reshape(data.shape[0])\n",
    "#         print(outputs.shape, label.shape)\n",
    "        sum_acc += torch.sum(outputs == label.reshape(data.shape[0]))\n",
    "        label = label.reshape(data.shape[0])\n",
    "        for i in range(outputs.shape[0]):\n",
    "            if outputs[i] == label[i] and label[i] == 1:\n",
    "                TP += 1\n",
    "            elif outputs[i] == label[i] and label[i] == 0:\n",
    "                TN += 1\n",
    "            elif outputs[i] != label[i] and label[i] == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        sum_all += data.shape[0]\n",
    "#     print('\\t\\t\\ttotal validation set data:{}, numbers of accurately labeled data:{}'.format(sum_all, sum_acc.detach()))\n",
    "    acc = sum_acc / sum_all\n",
    "    net.train()\n",
    "    if (TP + FN) == 0:\n",
    "        sensitivity = 0\n",
    "    else:\n",
    "        sensitivity = TP / (TP + FN)\n",
    "    if (FP + TN) == 0:\n",
    "        specificity = 0\n",
    "    else:\n",
    "        specificity = TN / (FP + TN)\n",
    "    return acc, sensitivity, specificity\n",
    "class generator(nn.Module):\n",
    "    def __init__(self,n_input, n_feature):\n",
    "        super(generator, self)\n",
    "        self.linear1 = nn.Linear(n_input, n_features[0])\n",
    "        self.linear2 = nn.Linear(n_features[0], n_features[1])\n",
    "        self.linear3 = nn.Linear(n_features[1], 4095)\n",
    "    def forward(x):\n",
    "        x = nn.LeakyReLU(self.linear1(x), inplace=True)\n",
    "        x = nn.LeakyReLU(self.linear2(x), inplace=True)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(MLP, self).__init__()\n",
    "#         nn.conv1 = \n",
    "#         resnet18 = models.resnet18(pretrained=True)\n",
    "#         resnet18.fc = nn.Linear(512, 2)\n",
    "        self.linear1 = nn.Linear(n_feature, 1000)\n",
    "        self.linear3 = nn.Linear(1000, 100)\n",
    "#         self.linear4 = resnet18.fc\n",
    "        self.linear4 = nn.Linear(100, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Xavier initialization for the fully connected layer\n",
    "        \"\"\"\n",
    "        self.linear1.weight.data.uniform_(-1, 1)\n",
    "        self.linear1.bias.data.fill_(0)\n",
    "#         self.linear2.weight.data.uniform_(-1, 1)\n",
    "#         self.linear2.bias.data.fill_(0)\n",
    "        self.linear3.weight.data.uniform_(-1, 1)\n",
    "        self.linear3.bias.data.fill_(0)\n",
    "        self.linear4.weight.data.uniform_(-1, 1)\n",
    "        self.linear4.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.dropout(F.relu((self.linear1(x))))\n",
    "        out = F.dropout(F.relu(self.linear3(out)))\n",
    "        out = self.linear4(out)\n",
    "#         x = self.linear4(x)\n",
    "        return out\n",
    "    \n",
    "# # net = LinearNet(dim_input).to(device)\n",
    "# # print(net) # 使用print可以打印出网络的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #########  训练过程，可以不动它\n",
    "# class LabelSmoothSoftmaxCEV1(nn.Module):\n",
    "#     '''\n",
    "#     This is the autograd version, you can also try the LabelSmoothSoftmaxCEV2 that uses derived gradients\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, lb_smooth=0.1, reduction='mean', ignore_index=-100):\n",
    "#         super(LabelSmoothSoftmaxCEV1, self).__init__()\n",
    "#         self.lb_smooth = lb_smooth\n",
    "#         self.reduction = reduction\n",
    "#         self.lb_ignore = ignore_index\n",
    "#         self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, logits, label):\n",
    "#         '''\n",
    "#         Same usage method as nn.CrossEntropyLoss:\n",
    "#             >>> criteria = LabelSmoothSoftmaxCEV1()\n",
    "#             >>> logits = torch.randn(8, 19, 384, 384) # nchw, float/half\n",
    "#             >>> lbs = torch.randint(0, 19, (8, 384, 384)) # nhw, int64_t\n",
    "#             >>> loss = criteria(logits, lbs)\n",
    "#         '''\n",
    "#         # overcome ignored label\n",
    "#         logits = logits.float() # use fp32 to avoid nan\n",
    "#         with torch.no_grad():\n",
    "#             num_classes = logits.size(1)\n",
    "#             label = label.clone().detach()\n",
    "#             ignore = label.eq(self.lb_ignore)\n",
    "#             n_valid = ignore.eq(0).sum()\n",
    "#             label[ignore] = 0\n",
    "#             lb_pos, lb_neg = 1. - self.lb_smooth, self.lb_smooth / num_classes\n",
    "#             lb_one_hot = torch.empty_like(logits).fill_(\n",
    "#                 lb_neg).scatter_(1, label.unsqueeze(1), lb_pos).detach()\n",
    "\n",
    "#         logs = self.log_softmax(logits)\n",
    "#         loss = -torch.sum(logs * lb_one_hot, dim=1)\n",
    "#         loss[ignore] = 0\n",
    "#         if self.reduction == 'mean':\n",
    "#             loss = loss.sum() / n_valid\n",
    "#         if self.reduction == 'sum':\n",
    "#             loss = loss.sum()\n",
    "\n",
    "#         return loss\n",
    "\n",
    "\n",
    "# losses = []\n",
    "# accuracy = []\n",
    "# sensitivity = []\n",
    "# specificity = []\n",
    "# preds = []\n",
    "# labels = []\n",
    "# avg_accuracy = []\n",
    "# print_every = 100\n",
    "# print_loss_total = 0\n",
    "# for seed in range(1):\n",
    "#     random.seed(seed)\n",
    "#     mixed = np.concatenate((x_total, y_total.reshape((-1, 1))), axis = 1)\n",
    "#     random.shuffle(mixed)\n",
    "#     kfold = 10\n",
    "#     GTlist = None\n",
    "#     Problist = None\n",
    "#     for i in range(kfold):\n",
    "#         num_epochs = 10 # 训练的epoch\n",
    "#         dim_input = 4005\n",
    "#         ######### 实例化算法对象\n",
    "#         xx = MLP(dim_input).to(device)\n",
    "#         ######### 选择损失函数MSELoss\n",
    "#         criterion = LabelSmoothSoftmaxCEV1().to(device)\n",
    "#         ########### 选择minibatch SGD算法\n",
    "#         learning_rate = 0.001\n",
    "#         ########## 这里面的xxxx是算法对象的实例化，我们的优化算法固定为SGD，可选momentum和nesterov，lr为超参数需要调优\n",
    "#         optimizer = optim.Adam(xx.parameters(), lr=learning_rate)\n",
    "#         print('fold:{}'.format(i))\n",
    "#         x_val = mixed[meta_size * i:meta_size*(i+1), :dim_input]\n",
    "#         y_val = mixed[meta_size * i:meta_size*(i+1), dim_input:]\n",
    "#         x_train = np.concatenate((mixed[:meta_size*i, :dim_input], mixed[meta_size*(i+1):, :dim_input]), axis=0)\n",
    "#         y_train = np.concatenate((mixed[:meta_size*i, dim_input:], mixed[meta_size*(i+1):, dim_input:]), axis=0)\n",
    "#         train_data = Data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "#         # print(train_data[0][0].dtype)\n",
    "#         val_data = Data.TensorDataset(torch.Tensor(x_val), torch.Tensor(y_val))\n",
    "#     #     test_data = Data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "#         train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "#         val_loader = Data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "#     #     test_loader = Data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "#         for epoch in range(num_epochs):\n",
    "#             xx.train()\n",
    "# #             print('\\tEpoch:{}'.format(epoch+1))\n",
    "#             for index, (data1, label1) in enumerate(train_loader):\n",
    "#                 data = Variable(data1, requires_grad=True).to(device)\n",
    "#                 label = Variable(label1, requires_grad=True).to(device)\n",
    "#                 output = xx(data)\n",
    "# #                 print(output.shape, label.shape)\n",
    "# #                 label = label.squeeze()\n",
    "#         #         label = label.squeeze()\n",
    "#                 loss = criterion(output, label.detach().reshape(label.shape[0]).long())\n",
    "\n",
    "#                 print_loss_total += loss\n",
    "\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 for i in range(data.shape[0]):\n",
    "#                     preds.append(output[i, int(np.array(label[i].detach().cpu())[0])].detach().cpu())\n",
    "#                     labels.append(label[i].detach().cpu())\n",
    "#                 if index % print_every == 0:\n",
    "#                     print_loss_avg = print_loss_total / print_every\n",
    "#                     print('\\t\\tloss:{}'.format(print_loss_avg))\n",
    "#                     losses.append(print_loss_avg)\n",
    "#                     print_loss_total = 0\n",
    "#             acc, sen, spe = evaluate_accuracy(val_loader, xx)\n",
    "#             accuracy.append(acc)\n",
    "#             sensitivity.append(sen)\n",
    "#             specificity.append(spe)\n",
    "# #             if epoch % 10 == 0:\n",
    "#             print('\\tEpoch:{}, Accuracy:{}, Sensitivity:{}, Specificity:{}'.format(epoch+1, acc, sen, spe))\n",
    "#             print('\\n')\n",
    "#             tacc, _, _ = evaluate_accuracy(train_loader, xx)\n",
    "#             print('training accuracy:{}'.format(tacc))\n",
    "#         acc, sen, spe = evaluate_accuracy(val_loader, xx)\n",
    "#         avg_accuracy.append(acc)\n",
    "#     mean_accuracy = 0\n",
    "#     for i in avg_accuracy:\n",
    "#         mean_accuracy += i\n",
    "#     print('average_accuracy:{}'.format(mean_accuracy / kfold))\n",
    "# total_loader = Data.DataLoader(dataset = Data.TensorDataset(torch.Tensor(mixed[:,:dim_input]), torch.Tensor(mixed[:, dim_input:])), batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# tmp, _, _ = evaluate_accuracy(total_loader, xx)\n",
    "# print('total acc:', tmp)\n",
    "# tmp, _, _ = evaluate_accuracy(total_loader, xx)\n",
    "# print('total acc:', tmp)\n",
    "# avg_sen = 0\n",
    "# avg_spe = 0\n",
    "# for i, (sen, spe) in enumerate(zip(sensitivity, specificity)):\n",
    "#     avg_sen += sen\n",
    "#     avg_spe += spe \n",
    "# print('sensitivity:{}, specificity:{}'.format(avg_sen / len(sensitivity), avg_spe / len(specificity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现算法三（深度方法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "\t\tloss:0.0\n",
      "\tEpoch:1, Accuracy:0.125, Sensitivity:0.125, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.5675675868988037\n",
      "\t\tloss:115.45267486572266\n",
      "\tEpoch:2, Accuracy:0.5, Sensitivity:0.5, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.5270270109176636\n",
      "\t\tloss:98.05325317382812\n",
      "\tEpoch:3, Accuracy:0.5, Sensitivity:0.5, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.6081081032752991\n",
      "\t\tloss:79.45931243896484\n",
      "\tEpoch:4, Accuracy:0.875, Sensitivity:0.875, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.6756756901741028\n",
      "\t\tloss:118.14140319824219\n",
      "\tEpoch:5, Accuracy:0.5, Sensitivity:0.5, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7297297716140747\n",
      "\t\tloss:150.459228515625\n",
      "\tEpoch:6, Accuracy:0.75, Sensitivity:0.75, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7837837934494019\n",
      "\t\tloss:78.45235443115234\n",
      "\tEpoch:7, Accuracy:0.25, Sensitivity:0.25, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:32.44796371459961\n",
      "\tEpoch:8, Accuracy:0.75, Sensitivity:0.75, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.824324369430542\n",
      "\t\tloss:73.6486587524414\n",
      "\tEpoch:9, Accuracy:1.0, Sensitivity:1.0, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.824324369430542\n",
      "\t\tloss:101.53094482421875\n",
      "\tEpoch:10, Accuracy:0.625, Sensitivity:0.625, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "fold:1\n",
      "\t\tloss:63.06989288330078\n",
      "\tEpoch:1, Accuracy:1.0, Sensitivity:1.0, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.4729729890823364\n",
      "\t\tloss:71.1545181274414\n",
      "\tEpoch:2, Accuracy:1.0, Sensitivity:1.0, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.5540540814399719\n",
      "\t\tloss:57.332908630371094\n",
      "\tEpoch:3, Accuracy:0.625, Sensitivity:0.625, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.5945945978164673\n",
      "\t\tloss:48.37142562866211\n",
      "\tEpoch:4, Accuracy:0.375, Sensitivity:0.375, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.662162184715271\n",
      "\t\tloss:116.97622680664062\n",
      "\tEpoch:5, Accuracy:0.625, Sensitivity:0.625, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7027027010917664\n",
      "\t\tloss:62.76493453979492\n",
      "\tEpoch:6, Accuracy:0.5, Sensitivity:0.5, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.6756756901741028\n",
      "\t\tloss:59.543514251708984\n",
      "\tEpoch:7, Accuracy:0.25, Sensitivity:0.25, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "\t\tloss:24.93023681640625\n",
      "\tEpoch:8, Accuracy:0.375, Sensitivity:0.375, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7432432770729065\n",
      "\t\tloss:25.866535186767578\n",
      "\tEpoch:9, Accuracy:0.25, Sensitivity:0.25, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.6891891956329346\n",
      "\t\tloss:6.811717987060547\n",
      "\tEpoch:10, Accuracy:0.25, Sensitivity:0.25, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7027027010917664\n",
      "fold:2\n",
      "\t\tloss:45.02799606323242\n",
      "\tEpoch:1, Accuracy:0.625, Sensitivity:0.625, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:129.91064453125\n",
      "\tEpoch:2, Accuracy:0.5, Sensitivity:0.5, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.6891891956329346\n",
      "\t\tloss:113.84561157226562\n",
      "\tEpoch:3, Accuracy:0.375, Sensitivity:0.375, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7027027010917664\n",
      "\t\tloss:101.35160064697266\n",
      "\tEpoch:4, Accuracy:0.375, Sensitivity:0.375, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7162162065505981\n",
      "\t\tloss:46.1271858215332\n",
      "\tEpoch:5, Accuracy:0.75, Sensitivity:0.75, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7162162065505981\n",
      "\t\tloss:104.88876342773438\n",
      "\tEpoch:6, Accuracy:0.625, Sensitivity:0.625, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7567567825317383\n",
      "\t\tloss:76.79125213623047\n",
      "\tEpoch:7, Accuracy:0.375, Sensitivity:0.375, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.8378378748893738\n",
      "\t\tloss:69.28363037109375\n",
      "\tEpoch:8, Accuracy:0.75, Sensitivity:0.75, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7567567825317383\n",
      "\t\tloss:6.165835857391357\n",
      "\tEpoch:9, Accuracy:0.5, Sensitivity:0.5, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:21.439754486083984\n",
      "\tEpoch:10, Accuracy:0.625, Sensitivity:0.625, Specificity:0\n",
      "\n",
      "\n",
      "training accuracy:0.8513513803482056\n",
      "fold:3\n",
      "\t\tloss:16.810792922973633\n",
      "\tEpoch:1, Accuracy:0.875, Sensitivity:0.8333333333333334, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:99.4000244140625\n",
      "\tEpoch:2, Accuracy:0.375, Sensitivity:0.16666666666666666, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:85.68866729736328\n",
      "\tEpoch:3, Accuracy:0.5, Sensitivity:0.3333333333333333, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.5\n",
      "\t\tloss:111.14424896240234\n",
      "\tEpoch:4, Accuracy:0.25, Sensitivity:0.16666666666666666, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.5675675868988037\n",
      "\t\tloss:78.2562255859375\n",
      "\tEpoch:5, Accuracy:0.75, Sensitivity:0.8333333333333334, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.662162184715271\n",
      "\t\tloss:58.489959716796875\n",
      "\tEpoch:6, Accuracy:0.625, Sensitivity:0.6666666666666666, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.7567567825317383\n",
      "\t\tloss:71.82453155517578\n",
      "\tEpoch:7, Accuracy:0.75, Sensitivity:0.8333333333333334, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:80.97394561767578\n",
      "\tEpoch:8, Accuracy:0.75, Sensitivity:0.8333333333333334, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.7837837934494019\n",
      "\t\tloss:29.4575138092041\n",
      "\tEpoch:9, Accuracy:0.875, Sensitivity:0.8333333333333334, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:55.33009338378906\n",
      "\tEpoch:10, Accuracy:0.625, Sensitivity:0.8333333333333334, Specificity:0.0\n",
      "\n",
      "\n",
      "training accuracy:0.9054054021835327\n",
      "fold:4\n",
      "\t\tloss:36.17817687988281\n",
      "\tEpoch:1, Accuracy:0.5, Sensitivity:0.75, Specificity:0.25\n",
      "\n",
      "\n",
      "training accuracy:0.5945945978164673\n",
      "\t\tloss:82.92994689941406\n",
      "\tEpoch:2, Accuracy:0.375, Sensitivity:0.5, Specificity:0.25\n",
      "\n",
      "\n",
      "training accuracy:0.6081081032752991\n",
      "\t\tloss:77.09131622314453\n",
      "\tEpoch:3, Accuracy:0.5, Sensitivity:0.25, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.662162184715271\n",
      "\t\tloss:131.0577392578125\n",
      "\tEpoch:4, Accuracy:0.5, Sensitivity:0.5, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.6891891956329346\n",
      "\t\tloss:80.17029571533203\n",
      "\tEpoch:5, Accuracy:0.75, Sensitivity:0.75, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.7567567825317383\n",
      "\t\tloss:34.3980598449707\n",
      "\tEpoch:6, Accuracy:0.5, Sensitivity:0.25, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.6756756901741028\n",
      "\t\tloss:23.129114151000977\n",
      "\tEpoch:7, Accuracy:0.75, Sensitivity:0.5, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:53.85878372192383\n",
      "\tEpoch:8, Accuracy:0.375, Sensitivity:0.25, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "\t\tloss:29.029300689697266\n",
      "\tEpoch:9, Accuracy:0.75, Sensitivity:0.75, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "\t\tloss:16.297197341918945\n",
      "\tEpoch:10, Accuracy:0.5, Sensitivity:0.5, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "fold:5\n",
      "\t\tloss:38.81071090698242\n",
      "\tEpoch:1, Accuracy:0.5, Sensitivity:0.3333333333333333, Specificity:0.6\n",
      "\n",
      "\n",
      "training accuracy:0.5\n",
      "\t\tloss:57.04318618774414\n",
      "\tEpoch:2, Accuracy:0.375, Sensitivity:0.3333333333333333, Specificity:0.4\n",
      "\n",
      "\n",
      "training accuracy:0.6486486792564392\n",
      "\t\tloss:96.43035888671875\n",
      "\tEpoch:3, Accuracy:0.625, Sensitivity:0.3333333333333333, Specificity:0.8\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:115.80895233154297\n",
      "\tEpoch:4, Accuracy:0.625, Sensitivity:0.6666666666666666, Specificity:0.6\n",
      "\n",
      "\n",
      "training accuracy:0.7432432770729065\n",
      "\t\tloss:96.94261169433594\n",
      "\tEpoch:5, Accuracy:0.625, Sensitivity:0.6666666666666666, Specificity:0.6\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:59.39692687988281\n",
      "\tEpoch:6, Accuracy:0.75, Sensitivity:0.6666666666666666, Specificity:0.8\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:59.2856330871582\n",
      "\tEpoch:7, Accuracy:0.75, Sensitivity:0.3333333333333333, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.8108108043670654\n",
      "\t\tloss:46.74884796142578\n",
      "\tEpoch:8, Accuracy:0.75, Sensitivity:0.6666666666666666, Specificity:0.8\n",
      "\n",
      "\n",
      "training accuracy:0.824324369430542\n",
      "\t\tloss:74.6855239868164\n",
      "\tEpoch:9, Accuracy:0.5, Sensitivity:0.6666666666666666, Specificity:0.4\n",
      "\n",
      "\n",
      "training accuracy:0.8513513803482056\n",
      "\t\tloss:32.136512756347656\n",
      "\tEpoch:10, Accuracy:0.75, Sensitivity:1.0, Specificity:0.6\n",
      "\n",
      "\n",
      "training accuracy:0.8648648858070374\n",
      "fold:6\n",
      "\t\tloss:43.65473175048828\n",
      "\tEpoch:1, Accuracy:0.125, Sensitivity:1.0, Specificity:0.0\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:94.52849578857422\n",
      "\tEpoch:2, Accuracy:0.625, Sensitivity:1.0, Specificity:0.5714285714285714\n",
      "\n",
      "\n",
      "training accuracy:0.6891891956329346\n",
      "\t\tloss:201.6596221923828\n",
      "\tEpoch:3, Accuracy:0.125, Sensitivity:1.0, Specificity:0.0\n",
      "\n",
      "\n",
      "training accuracy:0.5945945978164673\n",
      "\t\tloss:34.34968185424805\n",
      "\tEpoch:4, Accuracy:0.5, Sensitivity:1.0, Specificity:0.42857142857142855\n",
      "\n",
      "\n",
      "training accuracy:0.7432432770729065\n",
      "\t\tloss:49.4208984375\n",
      "\tEpoch:5, Accuracy:0.875, Sensitivity:1.0, Specificity:0.8571428571428571\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:0.7432432770729065\n",
      "\t\tloss:110.44136810302734\n",
      "\tEpoch:6, Accuracy:0.625, Sensitivity:1.0, Specificity:0.5714285714285714\n",
      "\n",
      "\n",
      "training accuracy:0.8108108043670654\n",
      "\t\tloss:119.70387268066406\n",
      "\tEpoch:7, Accuracy:0.75, Sensitivity:0.0, Specificity:0.8571428571428571\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "\t\tloss:94.90531158447266\n",
      "\tEpoch:8, Accuracy:0.5, Sensitivity:1.0, Specificity:0.42857142857142855\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:38.18915557861328\n",
      "\tEpoch:9, Accuracy:1.0, Sensitivity:1.0, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.9189189672470093\n",
      "\t\tloss:51.06658172607422\n",
      "\tEpoch:10, Accuracy:0.5, Sensitivity:1.0, Specificity:0.42857142857142855\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "fold:7\n",
      "\t\tloss:35.374046325683594\n",
      "\tEpoch:1, Accuracy:0.5, Sensitivity:0.0, Specificity:0.6666666666666666\n",
      "\n",
      "\n",
      "training accuracy:0.6351351737976074\n",
      "\t\tloss:81.77010345458984\n",
      "\tEpoch:2, Accuracy:0.625, Sensitivity:0.5, Specificity:0.6666666666666666\n",
      "\n",
      "\n",
      "training accuracy:0.5675675868988037\n",
      "\t\tloss:125.75590515136719\n",
      "\tEpoch:3, Accuracy:0.625, Sensitivity:1.0, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.5540540814399719\n",
      "\t\tloss:75.18245697021484\n",
      "\tEpoch:4, Accuracy:0.75, Sensitivity:0.5, Specificity:0.8333333333333334\n",
      "\n",
      "\n",
      "training accuracy:0.662162184715271\n",
      "\t\tloss:80.79190826416016\n",
      "\tEpoch:5, Accuracy:0.5, Sensitivity:1.0, Specificity:0.3333333333333333\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "\t\tloss:76.21990966796875\n",
      "\tEpoch:6, Accuracy:0.75, Sensitivity:1.0, Specificity:0.6666666666666666\n",
      "\n",
      "\n",
      "training accuracy:0.7567567825317383\n",
      "\t\tloss:54.15868377685547\n",
      "\tEpoch:7, Accuracy:0.625, Sensitivity:0.5, Specificity:0.6666666666666666\n",
      "\n",
      "\n",
      "training accuracy:0.7432432770729065\n",
      "\t\tloss:37.34344482421875\n",
      "\tEpoch:8, Accuracy:0.75, Sensitivity:1.0, Specificity:0.6666666666666666\n",
      "\n",
      "\n",
      "training accuracy:0.8108108043670654\n",
      "\t\tloss:28.717809677124023\n",
      "\tEpoch:9, Accuracy:0.25, Sensitivity:0.0, Specificity:0.3333333333333333\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:42.80556106567383\n",
      "\tEpoch:10, Accuracy:0.5, Sensitivity:1.0, Specificity:0.3333333333333333\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "fold:8\n",
      "\t\tloss:22.642065048217773\n",
      "\tEpoch:1, Accuracy:0.5, Sensitivity:0.5, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.5405405759811401\n",
      "\t\tloss:93.54144287109375\n",
      "\tEpoch:2, Accuracy:0.75, Sensitivity:1.0, Specificity:0.5\n",
      "\n",
      "\n",
      "training accuracy:0.5810810923576355\n",
      "\t\tloss:174.45692443847656\n",
      "\tEpoch:3, Accuracy:0.75, Sensitivity:0.75, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.6486486792564392\n",
      "\t\tloss:57.39959716796875\n",
      "\tEpoch:4, Accuracy:0.625, Sensitivity:0.5, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:82.30243682861328\n",
      "\tEpoch:5, Accuracy:0.75, Sensitivity:0.5, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.6486486792564392\n",
      "\t\tloss:64.95281982421875\n",
      "\tEpoch:6, Accuracy:0.375, Sensitivity:0.75, Specificity:0.0\n",
      "\n",
      "\n",
      "training accuracy:0.7297297716140747\n",
      "\t\tloss:90.31710052490234\n",
      "\tEpoch:7, Accuracy:0.875, Sensitivity:1.0, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.8108108043670654\n",
      "\t\tloss:47.13563537597656\n",
      "\tEpoch:8, Accuracy:0.75, Sensitivity:0.75, Specificity:0.75\n",
      "\n",
      "\n",
      "training accuracy:0.7702702879905701\n",
      "\t\tloss:19.98708724975586\n",
      "\tEpoch:9, Accuracy:1.0, Sensitivity:1.0, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.7837837934494019\n",
      "\t\tloss:29.786882400512695\n",
      "\tEpoch:10, Accuracy:0.75, Sensitivity:0.5, Specificity:1.0\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "fold:9\n",
      "\t\tloss:44.24134826660156\n",
      "\tEpoch:1, Accuracy:0.25, Sensitivity:1.0, Specificity:0.14285714285714285\n",
      "\n",
      "\n",
      "training accuracy:0.6216216087341309\n",
      "\t\tloss:151.50502014160156\n",
      "\tEpoch:2, Accuracy:0.25, Sensitivity:1.0, Specificity:0.14285714285714285\n",
      "\n",
      "\n",
      "training accuracy:0.6351351737976074\n",
      "\t\tloss:33.62397766113281\n",
      "\tEpoch:3, Accuracy:0.25, Sensitivity:0.0, Specificity:0.2857142857142857\n",
      "\n",
      "\n",
      "training accuracy:0.5405405759811401\n",
      "\t\tloss:107.99679565429688\n",
      "\tEpoch:4, Accuracy:0.5, Sensitivity:0.0, Specificity:0.5714285714285714\n",
      "\n",
      "\n",
      "training accuracy:0.5540540814399719\n",
      "\t\tloss:117.6430435180664\n",
      "\tEpoch:5, Accuracy:0.625, Sensitivity:0.0, Specificity:0.7142857142857143\n",
      "\n",
      "\n",
      "training accuracy:0.7027027010917664\n",
      "\t\tloss:135.93560791015625\n",
      "\tEpoch:6, Accuracy:0.5, Sensitivity:0.0, Specificity:0.5714285714285714\n",
      "\n",
      "\n",
      "training accuracy:0.7972972989082336\n",
      "\t\tloss:95.40597534179688\n",
      "\tEpoch:7, Accuracy:0.125, Sensitivity:0.0, Specificity:0.14285714285714285\n",
      "\n",
      "\n",
      "training accuracy:0.7162162065505981\n",
      "\t\tloss:75.14977264404297\n",
      "\tEpoch:8, Accuracy:0.25, Sensitivity:0.0, Specificity:0.2857142857142857\n",
      "\n",
      "\n",
      "training accuracy:0.8378378748893738\n",
      "\t\tloss:67.49970245361328\n",
      "\tEpoch:9, Accuracy:0.5, Sensitivity:1.0, Specificity:0.42857142857142855\n",
      "\n",
      "\n",
      "training accuracy:0.8513513803482056\n",
      "\t\tloss:37.89311981201172\n",
      "\tEpoch:10, Accuracy:0.125, Sensitivity:0.0, Specificity:0.14285714285714285\n",
      "\n",
      "\n",
      "training accuracy:0.8513513803482056\n",
      "average_accuracy:0.5875000357627869\n",
      "total acc: tensor(0.8293, device='cuda:0')\n",
      "total acc: tensor(0.8049, device='cuda:0')\n",
      "sensitivity:0.5937499999999999, specificity:0.4033809523809525\n"
     ]
    }
   ],
   "source": [
    "import learn2learn as l2l\n",
    "#########  训练过程，可以不动它\n",
    "import torch.nn.functional as F\n",
    "def evaluate_accuracy(loader, net):\n",
    "    net.eval()\n",
    "    sum_all = 0\n",
    "    sum_acc = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    \n",
    "    for index, (data, label) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            data = Variable(data, requires_grad=False).to(device)\n",
    "            label = Variable(label, requires_grad=False).to(device)\n",
    "        outputs = net(data).argmax(1).reshape(data.shape[0])\n",
    "#         print(outputs.shape, label.shape)\n",
    "        sum_acc += torch.sum(outputs == label.reshape(data.shape[0]))\n",
    "        label = label.reshape(data.shape[0])\n",
    "        for i in range(outputs.shape[0]):\n",
    "            if outputs[i] == label[i] and label[i] == 1:\n",
    "                TP += 1\n",
    "            elif outputs[i] == label[i] and label[i] == 0:\n",
    "                TN += 1\n",
    "            elif outputs[i] != label[i] and label[i] == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        sum_all += data.shape[0]\n",
    "#     print('\\t\\t\\ttotal validation set data:{}, numbers of accurately labeled data:{}'.format(sum_all, sum_acc.detach()))\n",
    "    acc = sum_acc / sum_all\n",
    "    net.train()\n",
    "    if (TP + FN) == 0:\n",
    "        sensitivity = 0\n",
    "    else:\n",
    "        sensitivity = TP / (TP + FN)\n",
    "    if (FP + TN) == 0:\n",
    "        specificity = 0\n",
    "    else:\n",
    "        specificity = TN / (FP + TN)\n",
    "    return acc, sensitivity, specificity\n",
    "class generator(nn.Module):\n",
    "    def __init__(self,n_input, n_feature):\n",
    "        super(generator, self)\n",
    "        self.linear1 = nn.Linear(n_input, n_features[0])\n",
    "        self.linear2 = nn.Linear(n_features[0], n_features[1])\n",
    "        self.linear3 = nn.Linear(n_features[1], 4095)\n",
    "    def forward(x):\n",
    "        x = nn.LeakyReLU(self.linear1(x), inplace=True)\n",
    "        x = nn.LeakyReLU(self.linear2(x), inplace=True)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(MLP, self).__init__()\n",
    "#         nn.conv1 = \n",
    "#         resnet18 = models.resnet18(pretrained=True)\n",
    "#         resnet18.fc = nn.Linear(512, 2)\n",
    "        self.linear1 = nn.Linear(n_feature, 1000)\n",
    "        self.linear3 = nn.Linear(1000, 100)\n",
    "#         self.linear4 = resnet18.fc\n",
    "        self.linear4 = nn.Linear(100, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Xavier initialization for the fully connected layer\n",
    "        \"\"\"\n",
    "        self.linear1.weight.data.uniform_(-1, 1)\n",
    "        self.linear1.bias.data.fill_(0)\n",
    "#         self.linear2.weight.data.uniform_(-1, 1)\n",
    "#         self.linear2.bias.data.fill_(0)\n",
    "        self.linear3.weight.data.uniform_(-1, 1)\n",
    "        self.linear3.bias.data.fill_(0)\n",
    "        self.linear4.weight.data.uniform_(-1, 1)\n",
    "        self.linear4.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.dropout(F.relu((self.linear1(x))))\n",
    "        out = F.dropout(F.relu(self.linear3(out)))\n",
    "        out = self.linear4(out)\n",
    "#         x = self.linear4(x)\n",
    "        return out\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "preds = []\n",
    "labels = []\n",
    "avg_accuracy = []\n",
    "print_every = 100\n",
    "print_loss_total = 0\n",
    "for seed in range(1):\n",
    "    random.seed(seed)\n",
    "    mixed = np.concatenate((x_total, y_total.reshape((-1, 1))), axis = 1)\n",
    "    random.shuffle(mixed)\n",
    "    kfold = 10\n",
    "    GTlist = None\n",
    "    Problist = None\n",
    "    for i in range(kfold):\n",
    "        num_epochs = 10 # 训练的epoch\n",
    "        dim_input = 4005\n",
    "        ######### 实例化算法对象\n",
    "        xx = MLP(dim_input).to(device)\n",
    "        learning_rate = 0.001\n",
    "        learning_rate_maml = 0.001\n",
    "        xx = l2l.algorithms.MAML(xx, lr = learning_rate_maml).to(device)\n",
    "        ######### 选择损失函数MSELoss\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        ########### 选择minibatch SGD算法\n",
    "        ########## 这里面的xxxx是算法对象的实例化，我们的优化算法固定为SGD，可选momentum和nesterov，lr为超参数需要调优\n",
    "        optimizer = optim.Adam(xx.parameters(), lr=learning_rate)\n",
    "        print('fold:{}'.format(i))\n",
    "        x_val = mixed[meta_size * i:meta_size*(i+1), :dim_input]\n",
    "        y_val = mixed[meta_size * i:meta_size*(i+1), dim_input:]\n",
    "        x_train = np.concatenate((mixed[:meta_size*i, :dim_input], mixed[meta_size*(i+1):, :dim_input]), axis=0)\n",
    "        y_train = np.concatenate((mixed[:meta_size*i, dim_input:], mixed[meta_size*(i+1):, dim_input:]), axis=0)\n",
    "        train_data = Data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "        val_data = Data.TensorDataset(torch.Tensor(x_val), torch.Tensor(y_val))\n",
    "        train_data = l2l.data.MetaDataset(train_data)\n",
    "        val_data = l2l.data.MetaDataset(val_data)\n",
    "    #     test_data = Data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "        train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "        val_loader = Data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "    #     test_loader = Data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            xx.train()\n",
    "#             print('\\tEpoch:{}'.format(epoch+1))\n",
    "            for index, (data1, label1) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()    \n",
    "                data = Variable(data1, requires_grad=True).to(device)\n",
    "                label = Variable(label1, requires_grad=True).to(device)\n",
    "                clone_model = xx.clone()\n",
    "                error = criterion(clone_model(data), label.detach().reshape(label.shape[0]).long())\n",
    "                clone_model.adapt(error)\n",
    "#                 print(output.shape, label.shape)\n",
    "#                 label = label.squeeze()\n",
    "        #         label = label.squeeze()\n",
    "                output = clone_model(data)\n",
    "                loss = criterion(output, label.detach().reshape(label.shape[0]).long())\n",
    "\n",
    "                print_loss_total += loss\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                for i in range(data.shape[0]):\n",
    "                    preds.append(output[i, int(np.array(label[i].detach().cpu())[0])].detach().cpu())\n",
    "                    labels.append(label[i].detach().cpu())\n",
    "                if index % print_every == 0:\n",
    "                    print_loss_avg = print_loss_total / print_every\n",
    "                    print('\\t\\tloss:{}'.format(print_loss_avg))\n",
    "                    losses.append(print_loss_avg)\n",
    "                    print_loss_total = 0\n",
    "            acc, sen, spe = evaluate_accuracy(val_loader, xx)\n",
    "            accuracy.append(acc)\n",
    "            sensitivity.append(sen)\n",
    "            specificity.append(spe)\n",
    "#             if epoch % 10 == 0:\n",
    "            print('\\tEpoch:{}, Accuracy:{}, Sensitivity:{}, Specificity:{}'.format(epoch+1, acc, sen, spe))\n",
    "            print('\\n')\n",
    "            tacc, _, _ = evaluate_accuracy(train_loader, xx)\n",
    "            print('training accuracy:{}'.format(tacc))\n",
    "        acc, sen, spe = evaluate_accuracy(val_loader, xx)\n",
    "        avg_accuracy.append(acc)\n",
    "    mean_accuracy = 0\n",
    "    for i in avg_accuracy:\n",
    "        mean_accuracy += i\n",
    "    print('average_accuracy:{}'.format(mean_accuracy / kfold))\n",
    "total_loader = Data.DataLoader(dataset = Data.TensorDataset(torch.Tensor(mixed[:,:dim_input]), torch.Tensor(mixed[:, dim_input:])), batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "tmp, _, _ = evaluate_accuracy(total_loader, xx)\n",
    "print('total acc:', tmp)\n",
    "tmp, _, _ = evaluate_accuracy(total_loader, xx)\n",
    "print('total acc:', tmp)\n",
    "avg_sen = 0\n",
    "avg_spe = 0\n",
    "for i, (sen, spe) in enumerate(zip(sensitivity, specificity)):\n",
    "    avg_sen += sen\n",
    "    avg_spe += spe \n",
    "print('sensitivity:{}, specificity:{}'.format(avg_sen / len(sensitivity), avg_spe / len(specificity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具体训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #########  训练过程，可以不动它\n",
    "# mixed = np.concatenate((x_total, y_total.reshape((-1, 1))), axis = 1)\n",
    "# losses = []\n",
    "# accuracy = []\n",
    "# sensitivity = []\n",
    "# specificity = []\n",
    "# preds = []\n",
    "# labels = []\n",
    "# avg_accuracy = []\n",
    "# print_every = 30\n",
    "# print_loss_total = 0\n",
    "\n",
    "# total_loader = Data.DataLoader(dataset = Data.TensorDataset(torch.Tensor(mixed[:,:dim_input]), torch.Tensor(mixed[:, dim_input:])), batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# for i in range(kfold):\n",
    "#     print('fold:{}'.format(i))\n",
    "#     x_val = mixed[meta_size * i:meta_size*(i+1), :dim_input]\n",
    "#     y_val = mixed[meta_size * i:meta_size*(i+1), dim_input:]\n",
    "#     x_train = np.concatenate((mixed[:meta_size*i, :dim_input], mixed[meta_size*(i+1):, :dim_input]), axis=0)\n",
    "#     y_train = np.concatenate((mixed[:meta_size*i, dim_input:], mixed[meta_size*(i+1):, dim_input:]), axis=0)\n",
    "#     train_data = Data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "#     # print(train_data[0][0].dtype)\n",
    "#     val_data = Data.TensorDataset(torch.Tensor(x_val), torch.Tensor(y_val))\n",
    "# #     test_data = Data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "#     train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "#     val_loader = Data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "# #     test_loader = Data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         xx.train()\n",
    "#         print('\\tEpoch:{}'.format(epoch+1))\n",
    "#         for index, (data1, label1) in enumerate(train_loader):\n",
    "#             data = Variable(data1, requires_grad=True).to(device)\n",
    "#             label = Variable(label1, requires_grad=True).to(device)\n",
    "#             output = xx(data)\n",
    "#     #         label = label.squeeze()\n",
    "#             loss = criterion(output, label.detach())\n",
    "\n",
    "#             print_loss_total += loss\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             for i in range(data.shape[0]):\n",
    "#                 preds.append(output[i].detach().cpu())\n",
    "#                 labels.append(label[i].detach().cpu())\n",
    "#             if index % print_every == 0:\n",
    "#                 print_loss_avg = print_loss_total / print_every\n",
    "#                 print('\\t\\tloss:{}'.format(print_loss_avg))\n",
    "#                 losses.append(print_loss_avg)\n",
    "#                 print_loss_total = 0\n",
    "#         acc, sen, spe = evaluate_accuracy(val_loader, xx)\n",
    "#         accuracy.append(acc)\n",
    "#         sensitivity.append(sen)\n",
    "#         specificity.append(spe)\n",
    "#         print('\\tEpoch:{}, Accuracy:{}, Sensitivity:{}, Specificity:{}'.format(epoch+1, acc, sen, spe))\n",
    "#         print('\\n')\n",
    "#     acc, sen, spe = evaluate_accuracy(val_loader, xx)\n",
    "#     avg_accuracy.append(acc)\n",
    "# mean_accuracy = 0\n",
    "# for i in avg_accuracy:\n",
    "#     mean_accuracy += i\n",
    "# print('average_accuracy:{}'.format(mean_accuracy / kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_list = [losses, accuracy, sensitivity, specificity]\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(4):\n",
    "    plt.subplot(4, 1, i + 1)\n",
    "    plt.plot(plt_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC曲线可视化\n",
    "\n",
    "\n",
    "ROC曲线下的面积为AUC，这个面积（下面打印的结果）如果大于0.5就证明具有一定价值，越接近1越好。如果实验完全随机，那么面积就等于0.5，就相当于p用没有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5269146858301087\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxY0lEQVR4nO3dd5xU1fnH8c9DR0RUQKMUQUEFDCJuUGKJXUQFjYiomEBISIzGhv7sxCCxG2IhQTAEWxbFAhhRYgGxU6QI2BAFFkFWmijS5Pn9ce66w7JlFnbm7ux836/XvPa2ufe5szPzzDnn3nPM3RERkexVLe4AREQkXkoEIiJZTolARCTLKRGIiGQ5JQIRkSynRCAikuWUCKoIM5tnZsfFHUfczGyYmd2c5mOOMrPB6TxmqpjZhWb2vx18bpV9D5qZm1mruONIFdN9BBXPzL4A9gZ+AL4FXgIudfdv44yrqjGzPsBv3f3omOMYBeS5+00xx3EL0Mrde6fhWKOoBOecLmbmQGt3XxB3LKmgEkHqnOnuuwIdgMOA6+MNp/zMrEY2HjtOes0lFu6uRwU/gC+AkxLm7wJeSJg/EngbWAPMBo5LWLcn8G/gS2A1MDZh3RnArOh5bwPtix4T2Bf4HtgzYd1hwNdAzWj+N8CH0f4nAvslbOvAJcCnwOclnF83YF4Ux2SgTZE4rgfmR/v/N1CnHOdwLTAH2AjUAK4DPgPWRfs8O9q2DbCBwlLXmmj5KGBwNH0ckAcMAFYAy4C+CcdrCDwPfANMAwYDb5byfz064f+2BOiTcMyhwAtRnO8BByQ8775o+2+AGcAxCetuAZ4GHo/W/xboBLwTHWcZ8CBQK+E57YCXgVXAV8ANQBdgE7A5ej1mR9s2AP4V7WdpdI7Vo3V9gLeAIcDKaF2fgtcAsGjdiii2D4BDgP7RcTZFx3q+6PseqB7FVfC/mwE0K+F1LfbzAPyc8L5tFs0fSnhPHRzNF/veKObc1gALo/31if4XK4BfJ2w/ChgWva7rgNfZ/nPRKpquDdwDLI5e/2FA3bi/d3bqOyvuAKrio8gHomn0Abovmm8Sfei6EkpkJ0fzjaP1LwBPAnsANYFfRMsPi968R0Qfsl9Hx6ldzDFfA36XEM/dwLBoujuwgPBFWgO4CXg7YVuPPgx7FvfmBg4Evovirgn8X7S/WglxzAWaRft4i8Iv5mTOYVb03LrRsnMJya0acF507H2idX0o8sXN9olgCzAoirUrsB7YI1o/OnrsArQlfEEUmwiA/QhfEOdH+2oIdEg45krCF3gN4AlgdMJze0fb1yAkpeVEyZGQCDYDZ0XnWBc4nPDlWANoQUjaV0Tb1yd8qQ8A6kTzRyTs6/EicT8HPATUA/YCpgK/T3j9tgB/io5Vl20TwamEL/DdCUmhTcJr/+PrXML7/hrC+/6g6LmHAg2LeV3L+jz8lfB+rhvt79KE55b13tgC9CW81wYTvriHEr7IT4n+n7smnM864Nho/X0kvBfYNhEMAcYT3t/1CT8mbo/7e2envrPiDqAqPqIPxLfRG8uBV4Hdo3XXAo8V2X4i4UtxH2Ar0RdVkW3+CdxaZNnHFCaKxA/hb4HXomkjfMEdG82/CPRL2Ec1wpfjftG8AyeUcm43A08Vef5SCn/FfQH8IWF9V+CzcpzDb8p4bWcB3aPpPpSdCL4HaiSsX0H4kq1O+AI+KGFdiSUCQinnuRLWjQIeLnLOH5VyDquBQ6PpW4ApZZzzFQXHJiSimSVsdwsJiYDQTrWRhIQePX9Swuu3uMg+fnxNgROAT6LXq1pJr3OR933Be/Djgv9TGedW4uchmq5JSEYfENrarBzvjU8T1v2U8N7eO2HZSrZN5onJe1dCabOgNOJAK8Ln6Tu2LfF1poTSc6Y81EaQOme5e33Cl9HBQKNo+X7AuWa2puBBqHLYh/BLeJW7ry5mf/sBA4o8rxnhF1FRzwCdzWwfwi+crcAbCfu5L2Efqwhv7iYJz19SynntCywqmHH3rdH2JT1/UUKMyZzDNsc2s1+Z2ayE7Q+h8LVMxkp335Iwv57wIW9M+BWceLzSzrsZoRqiJMuLOQYAZna1mX1oZmujc2jAtudQ9JwPNLP/mtlyM/sGuC1h+7LiSLQf4Yt0WcLr9xChZFDssRO5+2uEaqmhwAozG25muyV57GTjLO3zgLtvJnxJHwLc69E3LyT13vgqYfr7aH9Fl+2aMP/ja+Hhwo5VbP/5akwoQc5IOO5L0fKMpUSQYu7+OuGNfE+0aAnhF9DuCY967n5HtG5PM9u9mF0tAf5a5Hm7uHtuMcdcDfyPUFy+gPBLxxP28/si+6nr7m8n7qKUU/qS8OEFwMyM8KFfmrBNs4Tp5tFzkj2HxA/6fsAI4FJCtcLuhGonSyLOsuQTqg6alhB3UUuAA8p7EDM7hlB91pNQ0tsdWEvhOcD25/FP4CPCVSq7EeraC7ZfAuxfwuGK7mcJoUTQKOH13s3d25XynG136H6/ux9OqDo7kFDlU+bzSP71Ku3zgJk1Af5MaGu618xqR8vLem/siB///2a2K6Hq58si23xNSCDtEuJt4OHCkIylRJAefwdONrNDCY2CZ5rZqWZW3czqmNlxZtbU3ZcRqm7+YWZ7mFlNMzs22scI4A9mdoQF9czsdDOrX8Ix/wP8CugRTRcYBlxvZu0AzKyBmZ1bjnN5CjjdzE40s5qEuuqNhMa+ApeYWVMz2xO4kdDmsSPnUI/whZMfxdqX8KuvwFdAUzOrVY74AXD3H4BngVvMbBczO5jwepXkCeAkM+tpZjXMrKGZdUjiUPUJCScfqGFmA4GyflXXJzTOfhvFdXHCuv8C+5jZFWZW28zqm9kR0bqvgBZmVi06x2WEHwT3mtluZlbNzA4ws18kETdm9rPof1WTUB2ygVC6LDhWSQkJ4GHgVjNrHf2v25tZw2K2K/HzEP3IGEVo7O5HaBu5NXpeWe+NHdHVzI6O3k+3Au+6+zYlpqgEPAIYYmZ7RcduYman7uSxY6VEkAbung88CgyM3ljdCb/y8gm/iK6h8H9xEaHu+iNCffYV0T6mA78jFNVXExpo+5Ry2PFAa2C5u89OiOU54E5gdFTtMBc4rRzn8jGh8fMBwq+jMwmXym5K2Ow/hC+ghYTqgcE7cg7uPh+4l3AFzVeEet63EjZ5jXD10nIz+zrZc0hwKaGaZjnwGJBLSGrFxbKYUPc/gFBlMIvQAFqWiYSqg08I1WQbKL0KCuBqQkluHeFLpyCR4u7rCA2qZ0ZxfwocH60eE/1daWbvR9O/AmpReBXX00TVLknYLTr+6ij2lYQLDyB8ObeNqkfGFvPcvxF+NPyPkNT+RWjw3UYZn4fLCNVYN0cl2r5AXzM7Jon3xo74D6H0sYrQYF/S/RjXEt6770afoVcIjeIZSzeUSYWycDPdb939lbhjKS8zuxP4ibv/Ou5YJL0sy26QK0olAslaZnZwVGVhZtaJUP3wXNxxiaSb7iSUbFafUB20L6F64V5gXKwRicRAVUMiIllOVUMiIlku46qGGjVq5C1atIg7DBGRjDJjxoyv3b3YG98yLhG0aNGC6dOnxx2GiEhGMbNFJa1T1ZCISJZTIhARyXJKBCIiWU6JQEQkyykRiIhkOSUCEZEsp0QgIpLllAhERLKcEoGISJZTIhARyXJKBCIiWU6JQEQkyykRiIhkuZQlAjMbaWYrzGxuCevNzO43swVmNsfMOqYqFhERKVkqSwSjgC6lrD8NaB09+gP/TGEsIiJSgpQlAnefAqwqZZPuwKMevAvsbmb7pCoeEZHKYMMGePttmDo17kgKxdlG0ARYkjCfFy3bjpn1N7PpZjY9Pz8/LcGJiFSkefPgggugbl046ii48ca4IyqUESOUuftwYDhATk6OxxyOiEhSvvsObrsNRoyAgt+whx0G558P3brFG1uiOBPBUqBZwnzTaJmISMabMQNycgrnO3SAf/wDOneOLaQSxVk1NB74VXT10JHAWndfFmM8IiI75Z134KyzwKwwCVxwAWzdCjNnVs4kACksEZhZLnAc0MjM8oA/AzUB3H0YMAHoCiwA1gN9UxWLiEgqbd0KvXrBmDFhfvfdwyM3F448Ms7IkpOyRODu55ex3oFLUnV8EZFU++or+OUvw1VABR5/HC68ML6YdoTuLBYR2QE33ABNmxYmgQEDYNOmzEsCkCFXDYmIVBbTp0OXLrByZZh/5plQKshkKhGIiCQhLy80/P7sZyEJ1KsHn3+e+UkAlAhEREq1eTNcdx00axYafyE0Cn/7LbRoEWtoFUZVQyIixVi8GNq2DTeFAdSvDw88ABddBNWq2E/oKnY6IiI7Z8sWuOQS2G+/kATatoVHH4UVK+DXv656SQBUIhAR2UbNmoXTVaEhOBlKBCIiwPz50LNnmK5XL9wjUK9evDGlixKBiGS1lSuhUaNtl82enT1JANRGICJZ6ttvQ8NvYhKYMAHc4YAD4osrDkoEIpJVnn8eTj45XAX0+ONh2WOPhf6CTjst3tjioqohEckKo0ZB34SuLWvVgt//Hu68MwwWk82UCESkSps4MXQJUeD88+Gee2DffeOLqbJRIhCRKmfzZnjqKejdu3DZoYeG+wHat48vrspKiUBEqoyNG2HQoHAH8Lp1YZkZvPde6CNIiqfGYhHJeK++Gn7p16kTxghetw7+7//CvQBbtyoJlEUlAhHJaJdcEsYCBth//3BT2IAB298bICVTIhCRjLRoERx8MGzYEObHjoXu3WMNKWOpakhEMs6114Zf/xs2QIMGsGyZksDOUCIQkYwybBjcdVeo+3/nHVizBn7yk7ijymyqGhKRjPD992GEsLFjw/zMmdChQ5wRVR1KBCJSqS1ZAmedBe+/H+Zr14aFC3VDWEVS1ZCIVDpLl8K990JODjRvHpJAmzbw7LOhZKAkULFUIhCRSmPjxtDx26RJhcuaNoWbb4b+/eOLq6pTiUBEKoW77w43hBUkgUsugfXrQ9WQkkBqqUQgIrHasAGaNYOvvw7z114Ld9wRb0zZRolARGKzZg3ssUeY3n9/mDUrjBMg6aWqIRFJu2++gauuKkwCAJ99piQQl5QmAjPrYmYfm9kCM7uumPXNzWySmc00szlm1jWV8YhIvL75Bo45JtwNPGQI7LknjB8fhoeU+KQsEZhZdWAocBrQFjjfzNoW2ewm4Cl3PwzoBfwjVfGISHy2boXrrw8J4M03w7J//jP0DnrmmfHGJqktEXQCFrj7QnffBIwGivYG4sBu0XQD4MsUxiMiaeYehoisXr2wAXjw4LD8D3+AGmqlrBRS+W9oAixJmM8DjiiyzS3A/8zsT0A94KTidmRm/YH+AM2bN6/wQEWk4j33HPzyl4XzjRrBjBnhBjGpXOJuLD4fGOXuTYGuwGNmtl1M7j7c3XPcPadx48ZpD1JEkucOffoUJoHzzw8DxeTnKwlUVqksESwFmiXMN42WJeoHdAFw93fMrA7QCFiRwrhEJEXeeQd+8YswZjDA3LnQrl28MUnZUlkimAa0NrOWZlaL0Bg8vsg2i4ETAcysDVAHyE9hTCKSAl98EcYD+PnPQxL4y1/ghx+UBDJFykoE7r7FzC4FJgLVgZHuPs/MBgHT3X08MAAYYWZXEhqO+7jrQjKRTOAOjz0G998f6v4B6taF3FwNEpNpUtpm7+4TgAlFlg1MmJ4PHJXKGESk4s2bB4ccUjjftm3oLbRLl/hikh0Xd2OxiGSQLVvgoosKk8Dpp8OKFSExKAlkLiUCESnTxo1w9tlQsyY8/ni4FDQ3F/77X9CFfJlPt3OISInmzIEePeDTTwuXnXUWjBmjm8GqEpUIRGQ7s2aFBt9DDy1MAoMGha4inntOSaCq0b9TRLYxcCDcemuY3mef0CeQrgKq2pJOBGa2i7uvT2UwIhKfFSugX79Q7w/w3nvQqVO8MUl6lFk1ZGY/N7P5wEfR/KFmpl5CRaqILVvgsstg771DEjjnnHBfgJJA9kimRDAEOJXormB3n21mx6Y0KhFJuc2b4dxzYdy4wmVPPAEXXBBfTBKPpBqL3X1JkUU/pCAWEUmT4cOhVq3CJPDLX4ZLRJUEslMyJYIlZvZzwM2sJnA58GFqwxKRVLnsMnjggTB9+unhKqCaNeONSeKVTCL4A3AfYXyBpcD/gD+mMigRqXiffAJHHgmrV8N++8Err0CrVnFHJZVBMongIHe/MHGBmR0FvJWakESkovXtG0YKg3BX8Jw5sNtupT5FskgybQQPJLlMRCqZzZtDVdCoUVCtGjz7bBggRklAEpVYIjCzzsDPgcZmdlXCqt0I3UqLSCU2eXJoA1i/HnbfHZYvh9q1445KKqPSSgS1gF0JyaJ+wuMboEfqQxORHeEeegg9/viQBC67DJYuVRKQkpVYInD314HXzWyUuy9KY0wisoPefRf694cPPoA2bWD0aGjfPu6opLJLprF4vZndDbQjDCUJgLufkLKoRKRc3OHoo+Htt8P8b38LDz0U2gVEypJMIngCeBI4g3Ap6a/RuMIilcYPP4QxAVavDvPz54fSgEiykvm90NDd/wVsdvfX3f03gEoDIpXAihWwxx6FSWDTJiUBKb9kEsHm6O8yMzvdzA4D9kxhTCKShNdeCx3FrVsXuojYulV3CMuOSSYRDDazBsAA4GrgYeCKVAYlIiVbsgQOOwxOPDHM33YbPPMMmMUbl2SuMtsI3D3qnZy1wPHw453FIpJG7nD55YX9BAG8+SYcpU+j7KQSSwRmVt3Mzjezq83skGjZGWb2NvBg2iIUEQBOOaUwCVx/fWgkVhKQilBaieBfQDNgKnC/mX0J5ADXufvYNMQmIoSSwFlnhU7iIDQQN24ca0hSxZSWCHKA9u6+1czqAMuBA9x9ZXpCE5Hly0OPoYuiWzonT1YSkIpXWiLY5O5bAdx9g5ktVBIQSZ+1a8Pg8QCnnQZjx4bBZEQqWmlXDR1sZnOixwcJ8x+Y2Zx0BSiSjYYODR3FAZx9NrzwgpKApE5pJYKdvi3FzLoQBrWpDjzs7ncUs01P4BbAgdnursHyJGu9914YLnLhwjB/8cXwj3/EG5NUfaV1OrdTHc2ZWXVgKHAykAdMM7Px7j4/YZvWwPXAUe6+2sz22pljimSqF1+E3r1h1aow37cvjBgB1dXhu6RBMn0N7ahOwAJ3XwhgZqOB7sD8hG1+Bwx199UA7r4ihfGIVEr33APXXBOmGzSAadOgdet4Y5Lsksq+CZsASxLm86JliQ4EDjSzt8zs3agqaTtm1t/MppvZ9Px89XcnVcPWrXDVVYVJ4NVXYc0aJQFJv6RKBGZWF2ju7h+n4PitgeOApsAUM/upu69J3MjdhwPDAXJycryCYxBJK/dwGegJCV03jh+/7bxIOpVZIjCzM4FZwEvRfAczG5/EvpcSbkgr0DRaligPGO/um939c+ATQmIQqbJOPbXwS79NG1i5Es48M96YJLslUzV0C6G+fw2Au88CWibxvGlAazNraWa1gF5A0QQyllAawMwaEaqKFiaxb5GMM3s2tGwJL78c5r/8MowdsKf68pWYJdUNtbuvLbKszOoZd98CXApMBD4EnnL3eWY2yMy6RZtNBFaa2XxgEnCNblqTqig3Fzp0gC++gP33D6WAgpvFROKWTBvBPDO7AKgeXe55GfB2Mjt39wnAhCLLBiZMO3BV9BCpkk4+ubCfoGefDTeIiVQmySSCPwE3AhuB/xB+xQ9OZVAiVcGWLaHaZ926MD9vHrRtG29MIsVJJhEc7O43EpKBiCTh/fehc+cwdGT9+vD11+oiQiqvZNoI7jWzD83s1oJxCUSkZLfeCocfHpJA796hPUBJQCqzZEYoO97MfgL0BB4ys92AJ91d1UMiCdauhfPOg4kTw/yYMdCjR7wxiSQjqTuL3X25u98P/IFwT8HA0p8hkj2+/x6uuy70FjpxYhgvIC9PSUAyRzI3lLUxs1uirqgfIFwx1DTlkYlUcps3w4ABsMsucOedYdngwfDVV9CkaGcqIpVYMo3FI4EngVPd/csUxyOSMZo0gfx8qFkTBg6EK6+EevXijkqk/JJpI+icjkBEMkm/fiEJnHJK6EK6Wiq7bxRJsRITgZk95e49oyqhxDuJjXAvWPuURydSCb3xBowcGabHjVMSkMxXWong8ujvGekIRCQT/OlP8OCDYfrZZ6FOnXjjEakIJf6Wcfdl0eQf3X1R4gP4Y3rCE6k8hgwpTAITJqirCKk6kinUnlzMstMqOhCRymrrVhg9OgwiA/Dmm3CaPgFShZTWRnAx4Zf//mY2J2FVfeCtVAcmUhnk5xeOGQAwaxYcemisIYlUuNJKBP8BziSMIXBmwuNwd++dhthEYrNmDfTvD3vtFZLAOefA558rCUjVVFpjsbv7F2Z2SdEVZranu69KYVwisXj99dAWMG5cmN91V7j+erjhhnjjEkml0hLBfwhXDM0gXD5qCesc2D+FcYmklTsMGgS33FK47MIL4bHHwKzEp4lUCSUmAnc/I/qbzLCUIhlrxgzo0iV0FQ3w97/D5ZeX+hSRKqXMO4vN7Chglrt/Z2a9gY7A3919ccqjE0mhNWvCwDEe3S552mlhSMkGDWINSyTtkrl89J/AejM7FBgAfAY8ltKoRFJo5swwXvAee4Qk0KRJGFh+wgQlAclOySSCLdHYwt2BB919KOESUpGM8+CD0LEjLF8OLVvCE0+ELqPbq8MUyWLJ9D66zsyuBy4CjjGzakDN1IYlUvESu4eYMwd++tN44xGpLJIpEZxHGLj+N+6+nDAWwd0pjUqkgt1xR2ES+OQTJQGRRGUmgujL/wmggZmdAWxw90dTHplIBXCHXr3CvQAAU6dC69bxxiRS2SQzQllPYCpwLmHc4vfMTIPwSaW3YgUccgg8+WT48p8/H372s7ijEql8kmkjuBH4mbuvADCzxsArwNOpDExkR23dCocfHvoFAjjhBHjlFd0YJlKSZBJBtYIkEFlJkoPei6Tb2rVw5JHw0UdhfupUlQJEypJMInjJzCYCudH8ecCE1IUksmNmz4YOHcJ006aweLFKASLJSKax+BrgIaB99Bju7tcms3Mz62JmH5vZAjO7rpTtzjEzN7OcZAMXKZCfH+4KLkgCvXopCYiUR2njEbQG7gEOAD4Arnb3pcnu2MyqA0MJA9vkAdPMbLy7zy+yXX3CsJjvlT98yXZXXAHDhsHGjbDvvmE84f3VHaJIuZRWIhgJ/Bc4h9AD6QPl3HcnYIG7L3T3TcBowt3JRd0K3AlsKOf+JYtNnw7HHw/33ReSwMsvh1KAkoBI+ZXWRlDf3UdE0x+b2fvl3HcTYEnCfB5wROIGZtYRaObuL5jZNSXtyMz6A/0BmjdvXs4wpKp55hnokXAB80cfwUEHxRePSKYrrURQx8wOM7OO0Rd23SLzOyXqquJvhI7sSuXuw909x91zGjduvLOHlgzlDjfdVJgEhgyBzZuVBER2VmklgmWEL+oCyxPmHTihjH0vBZolzDeNlhWoDxwCTLbQqvcTYLyZdXP36WWHLtlk/fpwGej8qIVp9Gg477x4YxKpKkobmOb4ndz3NKC1mbUkJIBewAUJ+18LNCqYN7PJhAZpJQHZxoAB8LfoJ8jBB8O0aWEISRGpGMncR7BD3H2LmV0KTASqAyPdfZ6ZDQKmu/v4VB1bqoatWwsHjwf417/gN7+JNyaRqihliQDA3SdQ5OYzdx9YwrbHpTIWySxffRVuCtuyJYwbMGVKmBeRipfSRCCyI+bPh3btwvS++8Jnn+nmMJFUSqb3UTOz3mY2MJpvbmadUh+aZKP//rcwCVx2GSxdqiQgkmrJdB73D6AzcH40v45wx7BIhXrhBTjzzDB97rnhZjERSb1kEsER7n4J0Z2/7r4aqJXSqCSruMNdd8EZZ4T5SZPgqafijUkkmyTTRrA56jfI4cfxCLamNCrJGi++CF27Fs7n5sJxx8UWjkhWSiYR3A88B+xlZn8FegA3pTQqqfI2bYLatQvnDzgAZs6E+vXji0kkW5WZCNz9CTObAZwIGHCWu3+Y8sikStq0KbQD/O9/hcvmz4c2beKLSSTbJXPVUHNgPfA8MB74LlomkrR16+DPfw6lgIIk8Pvfww8/KAmIxC2ZqqEXCO0DBtQBWgIfA+1SGJdUEVu3wqmnhjGDC1x2Gfz977osVKSySKZq6KeJ81HPo39MWURSZcyaBYcdVjj/wANw8cVQvXpsIYlIMcp9Z7G7v29mR5S9pWSz22+HG24I03vtBUuWQC1ddCxSKZWZCMzsqoTZakBH4MuURSQZLT8frr8+dBAH8PzzhfcHiEjllEyJIPGCvi2ENoNnUhOOZLJ334XOnQvndTWQSGYoNRFEN5LVd/er0xSPZKjBg+Hmm8P07bfDVVepKkgkU5SYCMysRjSmwFHpDEgyz4MPFiaBl14KVwmJSOYorUQwldAeMMvMxgNjgO8KVrr7symOTSq55cvhoovCpaG77AIffgjNdYeJSMZJpo2gDrCSMEZxwf0EDigRZLEHHgj3AxSYNk1JQCRTlZYI9oquGJpLYQIo4CmNSiq1U08tvDv4vvvgj3+EGhriSCRjlfbxrQ7syrYJoIASQZbZvBkuvRSGDy9cNns2tG8fX0wiUjFKSwTL3H1Q2iKRSskd5s7d9gt/773DskaN4otLRCpOaZ3OqSeYLLZ5MwwdCtWqFSaBVq3gm29CI7GSgEjVUVqJ4MS0RSGVTqdOoa8ggB494Lzz4Jxz1FGcSFVUYiJw91XpDEQqB3fo2DEkgfbt4c03NViMSFWnaz3kR3PmhJLAxo2wzz5hxLBqyYxqLSIZTR9zAeDcc+HQQ0MSOPRQ+OwzJQGRbKESQZZbtSoMHfn222H+tdfC4PFqCxDJHvrNl8Vyc6Fhw5AEWrWCxYvh+OOVBESyTUoTgZl1MbOPzWyBmV1XzPqrzGy+mc0xs1fNbL9UxiOFbrsNLrggTA8cCJ9+Cs2axRuTiMQjZVVDURfWQ4GTgTxgmpmNd/f5CZvNBHLcfb2ZXQzcBZyXqpgkdAx39dUwYUKYf/VVOOGEeGMSkXilskTQCVjg7gvdfRMwGuieuIG7T3L39dHsu0DTFMaT1TZtgj59oG3bkAT23z8MH6kkICKpTARNgCUJ83nRspL0A14sboWZ9Tez6WY2PT8/vwJDrPo2bICzzoLateGRR8KysWNhwQJoqrQrIlSSxmIz6w3kAHcXt97dh7t7jrvnNG7cOL3BZbBnnoEGDWDcOKhbN4wdsHUrdO+uBmERKZTKRLAUSGx+bBot24aZnQTcCHRz940pjCerDB4cuobYtAlGjYL16+HRR5UARGR7qbyPYBrQ2sxaEhJAL+CCxA3M7DDgIaCLu69IYSxZZcKEwqEjp0yBY46JNx4RqdxSViJw9y3ApcBE4EPgKXefZ2aDzKxbtNndhDEPxphZwZCYshPeew9OPz1MDxumJCAiZUvpncXuPgGYUGTZwITpk1J5/Gzz5JPQq1eYnjQp3CEsIlIWdTFRBWzcCF26wOTJYf6tt+DnP481JBHJIJXiqiHZMe7w0EOw++6FSeDBB5UERKR8VCLIUE89FQaLKTBwINxyi64KEpHyUyLIQF27wovRrXdHHw3PPx9KBSIiO0KJIMPccENhEpg7F9q1izceEcl8SgQZ5Ior4L77wvRHH8FBB8UajohUEWoszhD//ndhEhgzRklARCqOSgSV3KpVoSTw2GNh/tNPwyAyIiIVRYmgklq7Nnzhf/114bKCkcRERCqSqoYqoS++CFcBFSSBu+4KN4117hxnVCJSVSkRVDIjRkDLlmH6t78NN41dcw3UqhVvXCJSdalqqJL44Ydwl/All4T5l16CU0+NNyYRyQ4qEVQCt9wCNWoUJoGHH1YSEJH0USKI2ZAh8Je/hOnLL4fly6Ffv3hjEpHsoqqhGP3mN+H+AIAPPoBDDok3HhHJTkoEMdi6Fbp1gxdeCPMrV8Kee8Ybk4hkLyWCNJs5Ezp2LJyfN09JQETipTaCNPr008Ik0LEjfP89tG0bb0wiIkoEaeAe+gk68MAwP3IkzJgBderEG5eICKhqKOW+/hpycmDRojD/z39C377xxiQikkiJIIWmToUjjiicX7QImjePLx4RkeKoaihFPvmkMAk89li4UkhJQEQqIyWCCrZwIZx1VuF4Ab/7HfTurbGERaTyUtVQBVm5Erp3h7feCvMNGoQE8OCD8cYlIlIWJYKdtGEDHHkkzJ5duOzpp+Gcc+KLSUSkPFQ1tBMWL4a99w5JoEEDeOSR0BagJCAimUQlgh2wdSs88wz07BnmO3WCd96BakqrItvYvHkzeXl5bNiwIe5QskadOnVo2rQpNWvWTPo5SgTlNG/etp3D3Xor3HijGoNFipOXl0f9+vVp0aIFpg9Jyrk7K1euJC8vj5YFI1wlIaW/Yc2si5l9bGYLzOy6YtbXNrMno/XvmVmLVMazo1asgNNOg1122TYJrFwJN92kJCBSkg0bNtCwYUMlgTQxMxo2bFjuEljKEoGZVQeGAqcBbYHzzaxozzr9gNXu3goYAtyZqnh2xMaNcPDBoR3gpZdC30AnnRRuFHNXZ3EiyVASSK8deb1TWSLoBCxw94XuvgkYDXQvsk134JFo+mngRKtE75p27eDjj8P0PfeEtoGXX4af/SzeuEREKlIqE0ETYEnCfF60rNht3H0LsBZoWHRHZtbfzKab2fT8/PwUhbu9v/41DBu5cSMMGKAqIJFMNXbsWMyMjz766MdlkydP5owzzthmuz59+vD0008DoaH7uuuuo3Xr1nTs2JHOnTvz4osv7nQst99+O61ateKggw5i4sSJxW7Tp08fWrZsSYcOHejQoQOzZs0CYNy4cbRv354OHTqQk5PDm2++udPxQIY0Frv7cGA4QE5OjqfruOedl64jiUgq5ebmcvTRR5Obm8tfCsaGLcPNN9/MsmXLmDt3LrVr1+arr77i9ddf36k45s+fz+jRo5k3bx5ffvklJ510Ep988gnVq1ffbtu7776bHj16bLPsxBNPpFu3bpgZc+bMoWfPntsktx2VykSwFGiWMN80WlbcNnlmVgNoAKxMYUwiEpMrroDoh22F6dAB/v730rf59ttvefPNN5k0aRJnnnlmUolg/fr1jBgxgs8//5zatWsDsPfee9Oz4JrxHTRu3Dh69epF7dq1admyJa1atWLq1Kl07tw5qefvuuuuP05/9913Fdb+ksqqoWlAazNraWa1gF7A+CLbjAd+HU33AF5z97T94heRqm/cuHF06dKFAw88kIYNGzJjxowyn7NgwQKaN2/ObrvtVua2V1555Y9VOImPO+64Y7ttly5dSrNmhb+PmzZtytKlRX8fBzfeeCPt27fnyiuvZOPGjT8uf+655zj44IM5/fTTGTlyZJnxJSNlJQJ332JmlwITgerASHefZ2aDgOnuPh74F/CYmS0AVhGShYhUQWX9ck+V3NxcLr/8cgB69epFbm4uhx9+eIm/psv7K3vIkCE7HWNRt99+Oz/5yU/YtGkT/fv3584772TgwIEAnH322Zx99tlMmTKFm2++mVdeeWWnj5fSNgJ3nwBMKLJsYML0BuDcVMYgItlr1apVvPbaa3zwwQeYGT/88ANmxt13303Dhg1ZvXr1dts3atSIVq1asXjxYr755psySwVXXnklkyZN2m55r169uO66bW+fatKkCUuWFF5Dk5eXR5MmRa+hgX322QeA2rVr07dvX+65557ttjn22GNZuHAhX3/9NY0aNSo1xrKoUwQRqbKefvppLrroIhYtWsQXX3zBkiVLaNmyJW+88QatW7fmyy+/5MMPPwRg0aJFzJ49mw4dOrDLLrvQr18/Lr/8cjZt2gRAfn4+Y8aM2e4YQ4YMYdasWds9iiYBgG7dujF69Gg2btzI559/zqeffkqnTp22227ZsmVAuFN47NixHBLdybpgwQIKas/ff/99Nm7cSMOG211oWW4ZcdWQiMiOyM3N5dprr91m2TnnnENubi7HHnssjz/+OH379mXDhg3UrFmThx9+mAYNGgAwePBgbrrpJtq2bUudOnWoV68egwYN2ql42rVrR8+ePWnbti01atRg6NChP14x1LVrVx5++GH23XdfLrzwQvLz83F3OnTowLBhwwB45plnePTRR6lZsyZ169blySefrJAGY8u0ttmcnByfPn163GGISBI+/PBD2rRpE3cYWae4193MZrh7TnHbq2pIRCTLKRGIiGQ5JQIRSalMq37OdDvyeisRiEjK1KlTh5UrVyoZpEnBeAR16tQp1/N01ZCIpEzTpk3Jy8sjnZ1FZruCEcrKQ4lARFKmZs2a5RopS+KhqiERkSynRCAikuWUCEREslzG3VlsZvnAojQeshHwdRqPl246v8xVlc8NdH4VbT93b1zcioxLBOlmZtNLui27KtD5Za6qfG6g80snVQ2JiGQ5JQIRkSynRFC24XEHkGI6v8xVlc8NdH5pozYCEZEspxKBiEiWUyIQEclySgQRM+tiZh+b2QIz226wUTOrbWZPRuvfM7MWMYS5Q5I4t6vMbL6ZzTGzV81svzji3FFlnV/CdueYmZtZpbhkL1nJnJ+Z9Yz+h/PM7D/pjnFnJPH+bG5mk8xsZvQe7RpHnDvCzEaa2Qozm1vCejOz+6Nzn2NmHdMdIxC6Lc32B1Ad+AzYH6gFzAbaFtnmj8CwaLoX8GTccVfguR0P7BJNX5wp55bs+UXb1QemAO8COXHHXcH/v9bATGCPaH6vuOOu4PMbDlwcTbcFvog77nKc37FAR2BuCeu7Ai8CBhwJvBdHnCoRBJ2ABe6+0N03AaOB7kW26Q48Ek0/DZxoFTFqdOqVeW7uPsnd10ez7wLl68M2Xsn87wBuBe4ENqQzuAqQzPn9Dhjq7qsB3H1FmmPcGcmcnwO7RdMNgC/TGN9OcfcpwKpSNukOPOrBu8DuZrZPeqIrpEQQNAGWJMznRcuK3cbdtwBrgYZpiW7nJHNuifoRfqFkijLPLypuN3P3F9IZWAVJ5v93IHCgmb1lZu+aWZe0Rbfzkjm/W4DeZpYHTAD+lJ7Q0qK8n8+U0HgE8iMz6w3kAL+IO5aKYmbVgL8BfWIOJZVqEKqHjiOU5qaY2U/dfU2cQVWg84FR7n6vmXUGHjOzQ9x9a9yBVRUqEQRLgWYJ802jZcVuY2Y1CEXUlWmJbuckc26Y2UnAjUA3d9+YptgqQlnnVx84BJhsZl8Q6mHHZ1CDcTL/vzxgvLtvdvfPgU8IiSETJHN+/YCnANz9HaAOocO2qiCpz2eqKREE04DWZtbSzGoRGoPHF9lmPPDraLoH8JpHrT2VXJnnZmaHAQ8RkkAm1S9DGefn7mvdvZG7t3D3FoQ2kG7uPj2ecMstmffmWEJpADNrRKgqWpjGGHdGMue3GDgRwMzaEBJBVRn7cjzwq+jqoSOBte6+LN1BqGqIUOdvZpcCEwlXMYx093lmNgiY7u7jgX8RiqQLCI0/veKLOHlJntvdwK7AmKj9e7G7d4st6HJI8vwyVpLnNxE4xczmAz8A17h7JpRWkz2/AcAIM7uS0HDcJ0N+hGFmuYQk3Shq4/gzUBPA3YcR2jy6AguA9UDfWOLMkNdTRERSRFVDIiJZTolARCTLKRGIiGQ5JQIRkSynRCAikuWUCKRSMrMfzGxWwqNFKdt+WwHHG2Vmn0fHej+6g7W8+3jYzNpG0zcUWff2zsYY7afgdZlrZs+b2e5lbN8hk3rrlHjo8lGplMzsW3fftaK3LWUfo4D/uvvTZnYKcI+7t9+J/e10TGXt18weAT5x97+Wsn0fQm+rl1Z0LFJ1qEQgGcHMdo3GSnjfzD4ws+16GDWzfcxsSsIv5mOi5aeY2TvRc8eYWVlf0FOAVtFzr4r2NdfMroiW1TOzF8xsdrT8vGj5ZDPLMbM7gLpRHE9E676N/o42s9MTYh5lZj3MrLqZ3W1m06J+6X+fxMvyDlEHZWbWKTrHmWb2tpkdFN2pOwg4L4rlvCj2kWY2Ndq2uJ5aJdvE0fe1HnqU9SDcITsrejxHuAt+t2hdI8KdmAUl2m+jvwOAG6Pp6oR+hhoRvtjrRcuvBQYWc7xRQI9o+lzgPeBw4AOgHuHO63nAYcA5wIiE5zaI/k4mGuugIKaEbQpiPBt4JJquReh5si7QH7gpWl4bmA60LCbObxPObwzQJZrfDagRTZ8EPBNN9wEeTHj+bUDvaHp3Qr9E9eL+f+sR70NdTEhl9b27dyiYMbOawG1mdiywlfBLeG9gecJzpgEjo23HuvssM/sFYTCTt6LuM2oRfkkX524zu4nQj00/Qv82z7n7d1EMzwLHAC8B95rZnYTqpDfKcV4vAveZWW2gCzDF3b+PqqPam1mPaLsGhI7jPi/y/LpmNis6/w+BlxO2f8TMWhO6YahZwvFPAbqZ2dXRfB2gebQvyVJKBJIpLgQaA4e7+2YLPYnWSdzA3adEieJ0YJSZ/Q1YDbzs7ucncYxr3P3pghkzO7G4jdz9EwtjHHQFBpvZq+4+KJmTcPcNZjYZOBU4jzAQC4QRqv7k7hPL2MX37t7BzHYh9M9zCXA/YeCdSe5+dtSwPrmE5xtwjrt/nEy8kh3URiCZogGwIkoCxwPbjatsYazlr9x9BPAwYYjAd4GjzKygzr+emR2Y5DHfAM4ys13MrB6hWucNM9sXWO/ujxM67CtunNnNUcmkOE8SOhcrKF1A+FK/uOA5ZnZgdMxieRhR7jJggBV2i17QfXGfhE3XEarICkwE/mRR8chCz7OS5ZQIJFM8AeSY2QfAr4CPitnmOGC2mc0k/Nq+z93zCV+MuWY2h1AtdHAyB3T39wltB1MJbQYPu/tM4KfA1KiK5s/A4GKePhyYU9BYXMT/CIP/vOJheEYIiWs+8L6Fgc4foowSexTLHMLALXcBt0fnnvi8SUDbgsZiQsmhZhTbvGhespwuHxURyXIqEYiIZDklAhGRLKdEICKS5ZQIRESynBKBiEiWUyIQEclySgQiIlnu/wEzW4jHpmQfPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding=UTF-8\n",
    "from sklearn import metrics\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "# 这个GTlist是真实标签\n",
    "GTlist = labels\n",
    "# 这个是预测值，\n",
    "Problist = preds\n",
    "\n",
    "\n",
    "\n",
    "## 下面的不要改变\n",
    "fpr, tpr, thresholds = metrics.roc_curve(GTlist, Problist, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)  #auc为Roc曲线下的面积\n",
    "print(roc_auc)\n",
    "\n",
    "pylab.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "pylab.legend(loc='lower right')\n",
    "# plt.plot([0, 1], [0, 1], 'r--')\n",
    "pylab.xlim([-0.1, 1.1])\n",
    "pylab.ylim([-0.1, 1.1])\n",
    "pylab.xlabel('False Positive Rate') #横坐标是fpr\n",
    "pylab.ylabel('True Positive Rate')  #纵坐标是tpr\n",
    "pylab.title('Receiver operating characteristic example')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当所有超参数调整好的时候，在测试集上运行一次，作为最终的accuracy，请记录下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, sen, spe = evaluate_accuracy(test_loader, xx)\n",
    "print('Accuracy on test set:{}, \\tSensitivity on test set:{}, \\tSpecificity on test set:{}'.format(acc, sen, spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, sen, spe = evaluate_accuracy(total_loader, xx)\n",
    "print('Accuracy on total set:{}, \\tSensitivity on test set:{}, \\tSpecificity on test set:{}'.format(acc, sen, spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################### test\n",
    "# # clf = SVC(kernel='linear')\n",
    "# # clf.fit(x_total, y_total)\n",
    "# # pred = clf.predict(x_total)\n",
    "# print(np.sum(preds==labels))\n",
    "# # print(f\"Classification report for classifier {xx>0.5}:\\n\"\n",
    "# #       f\"{metrics.classification_report(labels, preds)}\\n\")\n",
    "# disp = metrics.plot_confusion_matrix(xx, x_train, y_train)\n",
    "# disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "# print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adni = sio.loadmat('ADNI.mat')\n",
    "x_positive = data_adni['NC']\n",
    "x_negative = data_adni['AD']\n",
    "x_total = np.concatenate((x_positive, x_negative), axis=0).astype(np.float)\n",
    "y_positive = np.ones(x_positive.shape[0])\n",
    "y_negative = np.zeros(x_negative.shape[0])\n",
    "y_total = np.concatenate((y_positive, y_negative), axis=0).astype(np.float)\n",
    "print('有{}个正样本，有{}个负样本，一共有{}个样本'.format(y_positive.shape[0], y_negative.shape[0], x_total.shape[0]))\n",
    "num_x_pos = x_positive.shape[0]\n",
    "num_x_neg = x_negative.shape[0]\n",
    "dim_input = x_positive.shape[1]\n",
    "print('x原本是只有一个特征的，为294维')\n",
    "print(x_positive.shape, x_negative.shape, x_total.shape, y_positive.shape, num_x_neg, num_x_pos, dim_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTD_90_200_fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_ftd = sio.loadmat('FTD_90_200_fMRI.mat')\n",
    "x_positive = data_ftd['NC']\n",
    "x_negative = data_ftd['FTD']\n",
    "x_total = np.concatenate((x_positive, x_negative), axis=0).astype(np.float)\n",
    "y_positive = np.ones(x_positive.shape[0])\n",
    "y_negative = np.zeros(x_negative.shape[0])\n",
    "y_total = np.concatenate((y_positive, y_negative), axis=0).astype(np.float)\n",
    "print('有{}个正样本，有{}个负样本，一共有{}个样本'.format(y_positive.shape[0], y_negative.shape[0], x_total.shape[0]))\n",
    "num_x_pos = x_positive.shape[0]\n",
    "num_x_neg = x_negative.shape[0]\n",
    "dim_input = x_positive.shape[1]\n",
    "print('x原本是只有一个特征的，为294维')\n",
    "print(x_positive.shape, x_negative.shape, x_total.shape, y_positive.shape, num_x_neg, num_x_pos, dim_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [np.nan, 1]\n",
    "x.remove(np.nan)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
